{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e61c7bba-7135-4cca-ae70-012e7a866a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import huggingface\n",
    "import torch\n",
    "from transformers import AutoTokenizer, BartForConditionalGeneration\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer, DataCollatorForSeq2Seq\n",
    "import time\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c289a06-9d70-4e47-9e85-2f07fd9dc731",
   "metadata": {},
   "source": [
    "#### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "226e1a69-4cd0-49be-97c6-fc6c69d297f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 287113\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 13368\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 11490\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"abisee/cnn_dailymail\", \"1.0.0\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697d0484-d0e1-4630-8836-519844972146",
   "metadata": {},
   "source": [
    "#### Check Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e2430be-7386-47df-99d2-a98fa73579d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ignorance really isn't bliss. But there are times when the lack of knowledge and expertise about a subject or place can actually serve to clear the mind and lead to some clarity and honesty in the debate on even the most complex matters. I'm certainly no expert on Ukraine. I'm not sure before this crisis that I could even name all of the countries that share its borders. But watching the ticktock of the debate on the issue this past week, I'm stunned by the lack of perspective and breathlessness in the discussion. Sadly, I've grown accustomed to the partisanship. It has become a permanent fixture of our analytical and policy landscape. But here are several things about the recent coverage and discussion on Ukraine that even my lack of expertise won't allow me to accept: . 1. We're back in the Cold War . Clearly, none of the resets have worked with Russian President Vladimir Putin. Whether it was President George W. Bush looking into his eyes and seeing his soul or Bob Gates finding a stone-cold killer there, Putin isn't Stalin, Khrushchev or Brezhnev. That's hardly a shocker. Nor are we still in that unique period when two superpowers with contrasting ideological systems under the threat of nuclear war clashed and fought by proxy from one end of the globe to the other. There's no doubt that the United States and Russia have major differences. But the issue is no longer ideological. Russian capitalism is here to stay, state-controlled and monitored though it may be. And what ideology exists has more to do with asserting Russian national interests than anything Marx or Lenin would have recognized. And in at least one respect, that's too bad. At least during much of the Cold War, from the 1970s on, there were rules, do's and don'ts that prevented situations like Ukraine. Are you in Crimea? Share your story with CNN iReport. We'll continue to struggle with Putin, to be sure. But the world's too small, the Europeans too dependent on Russia, and the realities of global interdependence too deep to imagine hitting the rewind button and turning the planet into an arena of conflict and competition. Would it make for a good video game? Yes. 2. Putin is Hitler . In the past week, I've heard people I admire and respect talk about Crimea as Munich and Putin as Hitler. Twain wrote that history doesn't repeat; it rhymes. But those rhythmic patterns aren't evident here, either. When we can't think of intelligent parallels in analyzing nations who do things America cannot abide, it seems we're drawn irresistibly to the Hitler trope. The same thing happens with Iran. And while I don't for a moment condone the vicious  Israel-baiting and hating of the mullahcracy in Tehran (and the anti-Semitism, too) to bring up Hitler not only trivializes the monstrosity of the evil and the magnitude of the crimes in his time, it imposes unrealistic challenges in ours. The unique challenge of Hitler demanded that he be stopped and the Nazi regime destroyed. We don't have to like the Putin government in Russia, or Supreme Leader Ali Khamenei's in Iran, to recognize that the magnitude of the threat is different. To compare them to Hitler is to urge the United States into a game that we don't want to play and can't win. As best I can figure, Putin is a clever and easily riled Russian nationalist who presides over what remains of an empire whose time has come and gone. He lives in reality, not in some megalomaniacal world. But he is prepared to assert Russia's interests in spheres where it matters, and to block the West's intrusion into those areas as best he can. Russia is his \"ideology.\" And on Ukraine, history and proximity give him cards to play. This man isn't a fanatic. Money, pleasure and power are too important to him. Any leader who is willing to be photographed shirtless on a horse, like some cover of Men's Health magazine, isn't going to shoot himself in the head or take cyanide in a bunker. This guy is way too hip (Russian style) and attached to the good life to be Hitler. And given Russia's own suffering at the hands of the Nazis, saying he is just makes matters worse. 3. It's all Obama's fault . President Barack Obama was never the catastrophic incompetent or Satan's finger on earth that his worst critics imagined nor the redeemer, savior, or great President that his most avid acolytes wanted. And yet the notion that Obama, through weak and feckless foreign policy, was responsible for Putin's move into Ukraine strains credulity to the breaking point. This urban legend that because of Benghazi and the \"red line\" affair in Syria, Putin was compelled to do something in Ukraine that he wouldn't have done had Obama acted differently, is absurd. The administration's foreign policy has often resembled a blend between a Marx Brothers movie and the Three Stooges. But on this one the charge is absurd, as is the notion that somehow Obama could have stopped him. When the Soviet Union invaded Hungary in 1956, there was no U.S. military response; ditto in 1968 when the Soviets put down Prague Spring in Czechoslovakia. Sometimes, geography really is destiny. Russia believed its vital interests in Ukraine were threatened and it had the means, will, and proximity to act on them. And it's about time we faced up to it. 4. Bombing Syria would have saved Ukraine . This notion that Obama's opponents have latched onto is, of course, unknowable. There are no rewind buttons in history. Counterfactuals are prime talking and debating points because they cannot be proven one way or the other. But to  argue that launching cruise missiles at Syrian military targets somehow would have deterred Putin from acting on what he perceived to be a Russian vital interest, or emboldened the Europeans to stand tougher against him, really is off base. Syria and Ukraine are like apples and oranges the President's detractors insist on putting in the same basket.  Even if Obama thought the U.S. had vital interests that justified an attack on Syria, it is likely it would not have altered Putin's policy toward Ukraine. The country perceived to be in Russia's zone of influence and manipulation was drifting westward. And Putin was determined to stop it. 5. Ukraine can have a 'Hollywood' ending . Are there good guys and bad guys in the Ukraine-Russian drama? Sure there are. We have courageous Ukrainian patriots who died in the Maidan for the dignity and freedom they believed in; corrupt and ruthless government officials who were willing to use force against their own citizens; Russian provocateurs eager to stir up trouble; extremist Ukrainian nationalists who are hardly democrats; and a Russian strongman who hosted the Olympics one week and invaded the territory of a sovereign country the next. I suspect that the Ukrainian Spring -- if that's what it is  -- may turn out better than its Arab counterpart. But we have to be real. Ukraine may be fractious and troubled for some time to come. Below the morality play there is intense factionalism; regional differences; scores to settle; Russian manipulation; and a tendency to avoid the kind of compromise that would lead to real power sharing and good governance. We like Hollywood endings. But real democratization depends less on a friendly U.S. or EU hand than on the emergence of genuine leaders who are prepared to rise above factional affinities and see a vision for the country as  a whole. It also depends on institutions that reflect popular will and some mechanism for accommodating differences peacefully without resorting to violence. There are no easy or happy endings here. And we can only make matters worse, as Henry Kissinger suggested recently, by trying to turn the Ukraine crisis into a Russia vs. the West  (or worse, the U.S.) tug-of-war.</td>\n",
       "      <td>Aaron Miller says even those with little knowledge of Ukraine should spot the myths we've heard . He says Obama's foreign policy isn't to blame for what Putin did in Crimea . Miller says this doesn't represent a new Cold War, nor is Putin equivalent to Hitler . He says the outcome may be acceptable eventually but don't expect a Hollywood ending .</td>\n",
       "      <td>b462bafbd5f2f13fc214da313ad9d9fc90212bbd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARNOLD, Missouri (CNN)  -- On his 100th day in office, President Obama said Wednesday that he was \"pleased with the progress we've made but not satisfied.\" Obama marked his 100th day in office Wednesday with a town hall meeting and later a news conference. \"I've come back to report to you, the American people, that we have begun to pick ourselves up and dust ourselves off, and we've begun the work of remaking America,\" the president said at a town hall meeting in a high school gymnasium in Arnold, a St. Louis suburb. \"I'm confident in the future, but not I'm not content with the present,\" he said. \"You know the progress comes from hard choices and hard work, not miracles. I'm not a miracle worker,\" he said. Obama acknowledged challenges of \"unprecedented size and scope,\" including the recession. These challenges, he said, could not be met with \"half measures.\" \"They demand action that is bold and sustained. They call on us to clear away the wreckage of a painful recession, But also, at the same time, lay the building blocks for a new prosperity. And that's the work that we've begun over these first 100 days,\" he said. He responded to critics who say he is trying to do too much as he works to address the recession as well as health care, energy and education. \"There's no mystery to what we've done; the priorities that we've acted upon were the things that we said we'd do during the campaign,\" he said, prompting loud applause. The president made an opening statement that lasted about 20 minutes before taking questions from the audience. The last question was from a fourth-grade girl who asked about the administration's environmental policies. Later Wednesday, Obama will hold a prime-time news conference in the East Room of the White House. Leading up to the date, White House aides had labeled the 100th day as a \"Hallmark\" holiday. \"They don't mean anything,\" quipped one aide, \"but you have to observe them.\" More than six in 10 Americans approve of the job Obama is doing as president, a recent poll of polls shows. According to a CNN Poll of Polls compiled early Wednesday, 63 percent say they approve of how Obama is handling his duties. CNN's Ed Henry contributed to this report.</td>\n",
       "      <td>\"We've begun the work of remaking America,\" he says in Missouri . Obama warns that progress comes from \"hard work, not miracles\" He will hold a prime-time news conference later Wednesday .</td>\n",
       "      <td>70d29e642bc29b28c288363d41fa608493ef47e8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_random_elements(dataset, num_examples=2):\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, datasets.ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    display(HTML(df.to_html()))\n",
    "\n",
    "\n",
    "show_random_elements(dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d0c088-a8e0-4e7b-ba82-9c3e7676dfb3",
   "metadata": {},
   "source": [
    "These examples show that the news articles get summurised by in a fairly succinct fashion to give just the main highlights for each. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c80f39c-6c84-4052-929e-576a76d78f4f",
   "metadata": {},
   "source": [
    "#### Pre-process Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f319a9b1-5e39-4f5e-a00d-bd56dcae9ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tom_r\\anaconda3\\envs\\Generative_AI\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load model and tokenizer\n",
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd5adb44-feba-4681-90b0-a62994dca6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[0, 31414, 6, 42, 65, 3645, 328, 2], [0, 713, 16, 277, 3645, 4, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer(text_target=[\"Hello, this one sentence!\", \"This is another sentence.\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fb671c0-b12e-478d-ae9c-0d06bd559f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_function(examples):\n",
    "    #inputs = ['summarize' + doc for doc in examples[\"article\"]]\n",
    "    inputs = [doc for doc in examples[\"article\"]]\n",
    "    \n",
    "    model_inputs = tokenizer(inputs, max_length=512, truncation=True)\n",
    "\n",
    "    # Setup the tokenizer for targets\n",
    "    labels = tokenizer(text_target=examples[\"highlights\"], max_length=128, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_datasets = dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d1c7990-6be7-4d40-b2a4-df0401e86619",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[0, 574, 4524, 6, 1156, 36, 1251, 43, 480, 3268, 10997, 999, 3028, 7312, 20152, 3077, 899, 7, 10, 431, 984, 844, 153, 1358, 4006, 4, 134, 153, 43, 13016, 25, 37, 4072, 504, 15, 302, 6, 53, 37, 9838, 5, 418, 351, 75, 2471, 10, 8921, 15, 123, 4, 3028, 7312, 20152, 25, 3268, 10997, 11, 22, 29345, 10997, 8, 5, 9729, 9, 5, 5524, 113, 598, 5, 10208, 9, 20445, 6730, 1952, 198, 5, 232, 6, 5, 664, 2701, 161, 37, 34, 117, 708, 7, 856, 3961, 1334, 39, 1055, 409, 15, 1769, 1677, 6, 4076, 8, 6794, 1799, 4, 22, 100, 218, 75, 563, 7, 28, 65, 9, 167, 82, 54, 6, 25, 1010, 25, 51, 1004, 504, 6, 6017, 907, 1235, 10, 2232, 1612, 512, 2783, 50, 402, 1122, 60, 37, 174, 41, 2059, 33242, 656, 42, 353, 4, 22, 100, 218, 75, 206, 38, 581, 28, 1605, 31879, 4, 22, 133, 383, 38, 101, 2159, 32, 383, 14, 701, 59, 158, 2697, 480, 2799, 8, 32570, 8, 37206, 72, 497, 504, 6, 7312, 20152, 40, 28, 441, 7, 23104, 11, 10, 10297, 6, 907, 10, 4076, 11, 10, 8881, 50, 192, 5, 8444, 822, 22, 40534, 523, 35, 4657, 3082, 60, 855, 411, 2127, 874, 39, 346, 65, 1569, 15, 5, 987, 2233, 558, 5966, 4, 10574, 9, 141, 37, 581, 2458, 39, 10043, 4115, 32, 223, 18166, 4, 832, 2936, 8, 285, 661, 56, 117, 1129, 15, 39, 708, 4, 22, 100, 581, 2299, 33, 103, 2345, 9, 537, 60, 37, 26, 11, 41, 1194, 4, 22, 19204, 4146, 9, 47, 40, 28, 2600, 59, 24, 72, 7312, 20152, 18, 1107, 31, 5, 78, 292, 10997, 3541, 33, 57, 547, 11, 10, 2416, 1391, 61, 37, 34, 45, 57, 441, 7, 2842, 4, 2285, 39, 1197, 9444, 8, 33884, 6, 5, 2701, 161, 37, 16, 2396, 39, 1730, 10523, 15, 5, 1255, 4, 22, 4763, 32, 460, 546, 7, 224, 128, 30704, 999, 1411, 160, 5, 26717, 10076, 37, 174, 1865, 94, 353, 4, 22, 1708, 38, 860, 182, 543, 45, 7, 213, 14, 169, 142, 24, 74, 28, 350, 1365, 13, 106, 72, 832, 665, 9913, 25, 5, 2143, 32660, 11, 22, 29345, 10997, 8, 5, 9729, 9, 5, 5524, 113, 16, 3433, 2189, 15, 258, 2380, 9, 5, 5038, 8, 37, 40, 769, 22627, 5, 774, 11, 5, 94, 80, 3541, 4, 1437, 3075, 38, 12, 22026, 10679, 492, 69, 1551, 9, 10997, 18, 665, 9313, 479, 345, 16, 301, 1684, 10997, 6, 959, 4, 20, 928, 254, 34, 10571, 10, 1012, 1569, 373, 22, 2387, 5637, 2722, 60, 59, 2730, 19257, 2675, 11488, 20418, 8, 39, 979, 6, 528, 13, 800, 423, 42, 76, 4, 91, 40, 67, 2082, 11, 22, 17704, 8732, 60, 41, 2059, 822, 59, 237, 2786, 54, 5111, 41, 21297, 1580, 4, 3322, 42, 76, 6, 37, 156, 39, 1289, 2453, 816, 10, 20464, 7044, 11, 2155, 840, 16717, 18, 22, 28568, 687, 72, 2276, 6, 37, 16, 5378, 8988, 13, 190, 2789, 433, 7731, 122, 14, 37, 2], [0, 31611, 18, 1591, 35, 96, 84, 17285, 5, 40267, 651, 6, 3480, 20719, 4189, 458, 49, 3734, 11, 4631, 340, 8, 11526, 5, 1652, 639, 5, 1061, 4, 1398, 6, 4856, 196, 625, 384, 108, 9814, 1239, 1434, 1025, 10, 2878, 147, 171, 9, 5, 8039, 32, 10072, 4812, 4, 660, 12981, 15740, 15, 5, 22, 1990, 35095, 1929, 60, 147, 171, 10072, 4812, 8039, 32, 15740, 11, 2561, 137, 1500, 4, 10931, 17581, 6, 1261, 36, 16256, 43, 480, 20, 5127, 1929, 9, 5, 2561, 12, 495, 1829, 11857, 13700, 6848, 2122, 16, 9260, 5, 22, 1990, 35095, 1929, 72, 1398, 6, 8039, 19, 5, 144, 3814, 2536, 14971, 32, 24593, 454, 51, 214, 1227, 7, 2082, 11, 461, 4, 1993, 747, 6, 51, 652, 1262, 1103, 50, 1103, 9, 13511, 41, 1036, 480, 30364, 14, 3052, 5031, 1063, 1594, 397, 161, 32, 2333, 22, 40623, 868, 14383, 17130, 72, 91, 161, 5, 7102, 747, 898, 31, 10749, 1635, 19, 249, 4, 22150, 2368, 4812, 82, 747, 351, 75, 109, 99, 51, 214, 174, 77, 249, 5240, 15, 5, 1310, 480, 12065, 1302, 7, 33658, 49, 5467, 8, 51, 555, 55, 33554, 6, 40160, 6, 8, 540, 533, 7, 1407, 9969, 6, 309, 7, 1063, 1594, 397, 4, 407, 6, 51, 253, 62, 15, 5, 5127, 1929, 11166, 10072, 22938, 6, 53, 45, 562, 143, 588, 244, 142, 51, 214, 11, 2878, 4, 166, 20864, 5, 2878, 19, 1063, 1594, 397, 4, 91, 16, 157, 684, 11, 2561, 25, 41, 7156, 13, 2427, 8, 5, 10072, 4812, 4, 1648, 600, 52, 58, 45, 2230, 5340, 19, 490, 3701, 30, 5, 8528, 6, 52, 58, 576, 5537, 7, 4511, 32779, 5776, 8, 2106, 5, 1929, 4, 1437, 2381, 1025, 5, 128, 1990, 35095, 1929, 108, 9313, 479, 497, 78, 6, 24, 18, 543, 7, 3094, 147, 5, 82, 32, 4, 20, 9545, 32, 2498, 30145, 5536, 3361, 37928, 4, 15467, 3931, 6538, 13, 3701, 8, 1730, 11, 10, 2016, 24787, 8416, 3298, 480, 14, 18, 761, 9, 99, 51, 356, 101, 4, 252, 214, 1887, 7, 489, 5, 10072, 4812, 1484, 31, 14715, 1235, 4, 280, 18, 67, 596, 51, 33, 117, 5582, 6, 784, 11667, 50, 28648, 13937, 4, 1063, 1594, 397, 161, 59, 65, 12, 12347, 9, 70, 82, 11, 2561, 12, 495, 1829, 2109, 25559, 32, 10072, 4812, 4, 407, 6, 37, 161, 6, 5, 11708, 3149, 16, 8642, 5, 467, 6, 8, 5, 898, 16, 99, 52, 192, 15, 5, 5127, 1929, 4, 1525, 768, 6, 24, 16, 10, 2878, 6, 98, 24, 18, 45, 3518, 7, 28, 3279, 8, 29090, 6, 53, 5, 4666, 37355, 6, 5, 4590, 32, 5262, 8, 24, 18, 7337, 4, 166, 192, 80, 6, 2128, 130, 604, 480, 2128, 11, 5, 37928, 6, 2128, 12343, 6, 6480, 50, 2828, 11, 49, 4590, 4, 22, 100, 524, 5, 979, 9, 5, 394, 4, 370, 240, 7, 120, 162, 66, 9, 259, 2901, 65, 313, 32622, 23, 162, 4, 91, 16, 3668, 1473, 6, 7013, 14, 244, 16, 15, 5, 169, 480, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[0, 29345, 10997, 999, 3028, 7312, 20152, 1516, 984, 844, 448, 13016, 25, 37, 4072, 504, 302, 479, 2880, 2701, 161, 37, 34, 117, 708, 7, 856, 3961, 1334, 39, 1055, 409, 479, 7312, 20152, 18, 1107, 31, 78, 292, 10997, 3541, 33, 57, 547, 11, 2416, 1391, 479, 2], [0, 448, 1342, 2368, 4812, 8039, 11, 2561, 32, 15740, 15, 5, 22, 1990, 35095, 1929, 113, 3052, 5031, 1063, 1594, 397, 161, 144, 32, 89, 25, 10, 898, 9, 22, 40623, 868, 14383, 17130, 113, 616, 3480, 10182, 2122, 6, 3186, 32622, 35, 22, 100, 524, 5, 979, 9, 5, 394, 113, 1063, 1594, 397, 161, 5, 467, 16, 20134, 8, 37, 18, 2190, 13, 464, 479, 2]]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_function(dataset['train'][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "725c194a-226e-4e65-84a6-bd37a3533b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08a63598-c386-4c8c-add0-d31245f80d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENCODED SENTENCE:\n",
      "tensor([    0, 27847,     5, 19233,  6315,   173,    38,  5170,   116,     2])\n",
      "\n",
      "DECODED SENTENCE:\n",
      "Does the tokenizer work I wonder?\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Does the tokenizer work I wonder?\"\n",
    "\n",
    "sentence_encoded = tokenizer(sentence, return_tensors='pt')\n",
    "\n",
    "sentence_decoded = tokenizer.decode(\n",
    "        sentence_encoded[\"input_ids\"][0], \n",
    "        skip_special_tokens=True\n",
    "    )\n",
    "\n",
    "print('ENCODED SENTENCE:')\n",
    "print(sentence_encoded[\"input_ids\"][0])\n",
    "print('\\nDECODED SENTENCE:')\n",
    "print(sentence_decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc07520d-e8b5-4079-8d7f-6c61e86fd605",
   "metadata": {},
   "source": [
    "It does."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f06cf5-151c-44be-ae66-8374fa78ef92",
   "metadata": {},
   "source": [
    "#### Test out pre-trained BART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c842c8a3-3987-49a0-98b3-cd64b8a61f86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Example  1\n",
      "----------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "Norfolk, Virginia (CNN)The second mate of the Houston Express probably couldn't believe what he was seeing. Hundreds of miles from land there was a small boat nearby. At first it looked abandoned. It was in bad shape, listing to one side. The crew of the 1,000-foot long container ship thought it was a yacht that had wrecked. Incredibly, as they got closer, they saw there was a man on it, signaling for help. \"He was moving, walking around, waving to us and in surprisingly good condition,\" Capt. Thomas Grenz told CNN by phone Friday. That man, Louis Jordan, 37, had an amazing story. He'd been drifting on the 35-foot Pearson sailboat for more than two months since leaving Conway, South Carolina, to fish in the ocean. Just a few days into his trip, a storm capsized his boat and broke his mast. One of his shoulders was broken, too, so he couldn't fix the boat right away. Eventually he was able to rig a makeshift mast and sail, but he could make little headway against the currents. \"It took so long,\" Jordan said.  \"It moved so slowly.\" The boat capsized two more times before he was rescued, according to Jordan. His father, Frank Jordan, told CNN's Jim Sciutto that he was expecting his son to look different. \"He looked good. Hadn't lost too much weight. He wasn't badly sunburned like I thought he probably would be,\" he said. Lost at sea for 66 days . After his food and water ran out, it became an issue of survival. Collecting fresh water was a nightmare for Jordan.  The weather wouldn't cooperate. Records show there were more than a dozen storms off the coast of the Carolinas during the time he was missing. The precipitation came at night during harsh conditions. \"I had tried to collect (rain)water ... but every time the waves would splash into the boat,\" Jordan said.  \"The waves would put saltwater into my freshwater and it tasted bad. \"Finally the conditions were right.  I filled up my water tank, which is 25 gallons.  I filled up a bucket.\" Then there was the issue of food. The fish weren't cooperating, but after a while Jordan learned they were attracted to his laundry, which he would put out to sea for a rinse. The fish would swim in and out of his clothes and he could easily scoop them up with a hand net, he said. Jordan came ashore Thursday evening. CNN affiliate WAVY in Norfolk, Virginia, reported that he was able to walk from the helicopter into Sentara Norfolk General Hospital about 7:30 p.m. Coast Guard officials have said they have found no reason to doubt Jordan's incredible story. They noted that his father contacted them January 29 to report his son and his boat missing. Frank Jordan addressed the skepticism about his son's appearance, saying the boat stayed afloat and upright most of the time. His son spent most of his days in the cabin, out of the sun. Frank Jordan said it was obvious when the Jordans met at the hospital Friday morning that his normally low-key and private son had been through an ordeal. \"I know he went through what he went through,\" Frank Jordan said. Jordan is an unemployed truck driver who lived on his boat at a marina in Conway. He had free rent and free food in the river, he said. But when it became difficult to catch dinner, he took off for the ocean in hopes he would land some bigger fish. Frank Jordan told CNN's Wolf Blitzer on Thursday that he had worried about his son, who is an inexperienced sailor, but he held hope because his son had a good boat. And he had the strength to make it. \"He's got a very strong constitution and (is strong) not only physically, but spiritually,\" Frank Jordan said. \"And he told me on the phone that he was praying the whole time, so I believe that sustained him a great deal.\" Rescue swimmer Kyle McCollum was the first to care for Jordan on the flight back to land. \"You would expect sunburns, severe sunburn, blisters maybe ... a bunch of medical issues that could possibly be wrong with him,\" he said. \"But for him to be in his current state was pretty amazing.\" Grenz was also surprised by Jordan's condition, physically and mentally. The rescued sailor knew almost exactly what day it was, remarkable for someone who had been on the water for more than 60 days. Jordan was dehydrated and said he was hungry. \"We took him to a rescue boat,\" the container ship captain said. \"He was given water and pea soup to gain some power again.\" Derriel Morris, a neighbor at the Bucksport Plantation Marina & RV Resort called Jordan a nice guy who loved his 47-year-old boat, named \"Angel.\" Morris said: \"It was immaculate, it was gorgeous, beautifully painted. I mean it looked like a brand new sailboat.\" Morris told CNN affiliate WPDE that one day in January he was going to the store and Jordan asked him to bring back some coffee creamer. But when he returned to the marina, Jordan had slipped away. \"There was no shore line, no hose; it was like he was never there,\" Morris told the station. After he disappeared others who also live there held a candlelight ceremony. The marina's manager, Jeff Weeks, told WPDE that Jordan is expected to be back at Buscksport next week. Tales of people who cheated death after days, weeks adrift .\n",
      "----------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "Father: \"I know he went through what he went through\" Louis Jordan was found on his sailboat, which was listing and in bad shape, rescuer says . He appears to be in good shape, physically and mentally .\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Pre-Trained BART GENERATION - WITHOUT PROMPT ENGINEERING:\n",
      "Louis Jordan, 37, left Conway, South Carolina, to fish in the ocean. A storm capsized his boat and broke his mast, so he couldn't fix it right away. After his food and water ran out, it became an issue of survival. \"He was moving, walking around, waving to us and in surprisingly good condition,\" captain says.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Example  2\n",
      "----------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "(CNN)According to an outside review by Columbia Journalism School professors, \"(a)n institutional failure at Rolling Stone resulted in a deeply flawed article about a purported gang rape at the University of Virginia.\" The Columbia team concluded that \"The failure encompassed reporting, editing, editorial supervision and fact-checking.\" Hardly a ringing endorsement of the editorial process at the publication. The magazine's managing editor, Will Dana, wrote, \"We would like to apologize to our readers and to all of those who were damaged by our story and the ensuing fallout, including members of the Phi Kappa Psi fraternity and UVA administrators and students.\" Brian Stelter: Fraternity to 'pursue all available legal action' The next question is: . Can UVA, Phi Kappa Psi or any of the other fraternities on campus sue for defamation? The Virginia Supreme Court said in Jordan v. Kollman that \"the elements of libel are (1) publication of (2) an actionable statement with (3) the requisite intent.\" \"Actionable\" means the statement must be both false and defamatory. Of course, the law of defamation must be balanced against the freedom of speech protected under not only the First Amendment to the United States Constitution, but also the Virginia Constitution. True statements cannot be defamatory. Neither can pure statements of opinion, because they theoretically cannot be either true or false. But the Rolling Stone article certainly purported to be fact, and it apparently is not exactly what the law considers \"true.\" The individual members of the fraternity will likely be considered private individuals, and not public figures; the latter have a harder time proving defamation. A private person suing for defamation must establish that the defendant has published a false factual statement that is about the person and that it also harms the person's reputation. The private plaintiff also must show that the defendant knew that the statement was false, or believed it was true but lacked a reasonable basis, or acted negligently in checking the facts. At first blush, that sounds like it fits perfectly, right? The Columbia report may go a long way toward establishing at least a modicum of the required intent. But that's only half the battle. There are strict rules about who can be a plaintiff in a defamation action like this. The identity of the aspiring plaintiff matters. First, let's eliminate UVA. The university is a public university, and therefore it is a governmental entity. The Supreme Court has been clear on the issue of libelous statements about the government: The government cannot sue for defamation. There is no such cause of action in American jurisprudence. Now the fraternities, starting with Phi Kappa Psi. A fraternity is not an individual, but a group. A plaintiff in a defamation case must show that the statements were \"of or concerning\" the plaintiff. It sounds obvious, but if you're going to say a statement hurt you, you have to prove the statement actually was about you to begin with. When the statements are about a group without naming an individual, it's hard to say the statement is \"concerning\" the individual -- and groups generally cannot sue.  For example, you can be sued if you call a specific lawyer a thief, but that same person cannot sue you if you simply call all lawyers thieves. Defamatory statements about a group are therefore not actionable by the group's individual members, for the most part. Like all rules, however, there are exceptions. If the defamatory language is about \"a comparatively small group of persons and the defamatory part is easily imputed against all members of the small group, an individual member may sue.\" If I said, \"The 1980 Philadelphia Phillies infielders were a bunch of criminals\" (they weren't),  the individual players could sue, because that mean statement is clearly about certain persons -- if I said that -- which I didn't. Phi Kappa Psi would likely argue that the \"small group\" exception fits it perfectly: Even if the individual members were not identified by name, the defamatory story has been imputed directly to individual members, who have suffered by their association with the group. On the other hand, Rolling Stone's lawyers would likely argue that the group is so large and fluid (after all, the membership changes somewhat every year), that even though the fraternity's reputation is tarnished, the members have suffered no individualized injury. As for the other fraternities on campus but not implicated in the story, that's likely a group that moves from the small category to large, and the members of Greek life generally will have a harder time bringing a lawsuit. Lawyers will tell you that a libel suit is one of those things that citizens often threaten each other with on Facebook, but that such cases are rarely actually filed. That's because a plaintiff usually has to show some kind of financial harm. So if your Aunt Edna calls you a loser on Twitter, you're going to have to spend money on an expert to explain to a jury how that actually damaged you financially. And since most of the people who waste time threatening each other with defamation suits  on Facebook live in their moms' basements and are \"between jobs,\" these are not the kind of people who have money or reputation to damage in the first place. The UVA situation is not your run-of-the-mill defamation case. The university won't be able to sue, but if the members of the fraternity can get past some of the preliminary hurdles of a defamation claim, and they can make a tangible case for damages, then this could be one of those rare successful defamation cases.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "An outside review found that a Rolling Stone article about campus rape was \"deeply flawed\" Danny Cevallos says that there are obstacles to a successful libel case, should one be filed .\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Pre-Trained BART GENERATION - WITHOUT PROMPT ENGINEERING:\n",
      "Rolling Stone published an article about a purported gang rape at the University of Virginia. Peter Bergen: Can UVA, Phi Kappa Psi or any of the other fraternities on campus sue for defamation? He says the law of defamation must be balanced against the freedom of speech protected under the First Amendment.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_indices = [20, 50]\n",
    "dash_line = 100 * '-'\n",
    "\n",
    "\n",
    "for i, index in enumerate(example_indices):\n",
    "    dialogue = dataset['test'][index]['article']\n",
    "    summary = dataset['test'][index]['highlights']\n",
    "\n",
    "    prefix = 'Provide a very short summary of the following article: '\n",
    "    \n",
    "    inputs = tokenizer(dialogue, max_length=512, truncation=True, return_tensors='pt')\n",
    "    output = tokenizer.decode(\n",
    "        model.generate(\n",
    "            inputs[\"input_ids\"], \n",
    "            max_new_tokens=250,\n",
    "        )[0], \n",
    "        skip_special_tokens=True\n",
    "    )\n",
    "    \n",
    "    print(dash_line)\n",
    "    print('Example ', i + 1)\n",
    "    print(dash_line)\n",
    "    print(f'INPUT PROMPT:\\n{dialogue}')\n",
    "    print(dash_line)\n",
    "    print(f'BASELINE HUMAN SUMMARY:\\n{summary}')\n",
    "    print(dash_line)\n",
    "    print(f'Pre-Trained BART GENERATION - WITHOUT PROMPT ENGINEERING:\\n{output}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "19435e23-89df-454a-b273-7032ac660255",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Example  1\n",
      "----------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "Norfolk, Virginia (CNN)The second mate of the Houston Express probably couldn't believe what he was seeing. Hundreds of miles from land there was a small boat nearby. At first it looked abandoned. It was in bad shape, listing to one side. The crew of the 1,000-foot long container ship thought it was a yacht that had wrecked. Incredibly, as they got closer, they saw there was a man on it, signaling for help. \"He was moving, walking around, waving to us and in surprisingly good condition,\" Capt. Thomas Grenz told CNN by phone Friday. That man, Louis Jordan, 37, had an amazing story. He'd been drifting on the 35-foot Pearson sailboat for more than two months since leaving Conway, South Carolina, to fish in the ocean. Just a few days into his trip, a storm capsized his boat and broke his mast. One of his shoulders was broken, too, so he couldn't fix the boat right away. Eventually he was able to rig a makeshift mast and sail, but he could make little headway against the currents. \"It took so long,\" Jordan said.  \"It moved so slowly.\" The boat capsized two more times before he was rescued, according to Jordan. His father, Frank Jordan, told CNN's Jim Sciutto that he was expecting his son to look different. \"He looked good. Hadn't lost too much weight. He wasn't badly sunburned like I thought he probably would be,\" he said. Lost at sea for 66 days . After his food and water ran out, it became an issue of survival. Collecting fresh water was a nightmare for Jordan.  The weather wouldn't cooperate. Records show there were more than a dozen storms off the coast of the Carolinas during the time he was missing. The precipitation came at night during harsh conditions. \"I had tried to collect (rain)water ... but every time the waves would splash into the boat,\" Jordan said.  \"The waves would put saltwater into my freshwater and it tasted bad. \"Finally the conditions were right.  I filled up my water tank, which is 25 gallons.  I filled up a bucket.\" Then there was the issue of food. The fish weren't cooperating, but after a while Jordan learned they were attracted to his laundry, which he would put out to sea for a rinse. The fish would swim in and out of his clothes and he could easily scoop them up with a hand net, he said. Jordan came ashore Thursday evening. CNN affiliate WAVY in Norfolk, Virginia, reported that he was able to walk from the helicopter into Sentara Norfolk General Hospital about 7:30 p.m. Coast Guard officials have said they have found no reason to doubt Jordan's incredible story. They noted that his father contacted them January 29 to report his son and his boat missing. Frank Jordan addressed the skepticism about his son's appearance, saying the boat stayed afloat and upright most of the time. His son spent most of his days in the cabin, out of the sun. Frank Jordan said it was obvious when the Jordans met at the hospital Friday morning that his normally low-key and private son had been through an ordeal. \"I know he went through what he went through,\" Frank Jordan said. Jordan is an unemployed truck driver who lived on his boat at a marina in Conway. He had free rent and free food in the river, he said. But when it became difficult to catch dinner, he took off for the ocean in hopes he would land some bigger fish. Frank Jordan told CNN's Wolf Blitzer on Thursday that he had worried about his son, who is an inexperienced sailor, but he held hope because his son had a good boat. And he had the strength to make it. \"He's got a very strong constitution and (is strong) not only physically, but spiritually,\" Frank Jordan said. \"And he told me on the phone that he was praying the whole time, so I believe that sustained him a great deal.\" Rescue swimmer Kyle McCollum was the first to care for Jordan on the flight back to land. \"You would expect sunburns, severe sunburn, blisters maybe ... a bunch of medical issues that could possibly be wrong with him,\" he said. \"But for him to be in his current state was pretty amazing.\" Grenz was also surprised by Jordan's condition, physically and mentally. The rescued sailor knew almost exactly what day it was, remarkable for someone who had been on the water for more than 60 days. Jordan was dehydrated and said he was hungry. \"We took him to a rescue boat,\" the container ship captain said. \"He was given water and pea soup to gain some power again.\" Derriel Morris, a neighbor at the Bucksport Plantation Marina & RV Resort called Jordan a nice guy who loved his 47-year-old boat, named \"Angel.\" Morris said: \"It was immaculate, it was gorgeous, beautifully painted. I mean it looked like a brand new sailboat.\" Morris told CNN affiliate WPDE that one day in January he was going to the store and Jordan asked him to bring back some coffee creamer. But when he returned to the marina, Jordan had slipped away. \"There was no shore line, no hose; it was like he was never there,\" Morris told the station. After he disappeared others who also live there held a candlelight ceremony. The marina's manager, Jeff Weeks, told WPDE that Jordan is expected to be back at Buscksport next week. Tales of people who cheated death after days, weeks adrift .\n",
      "----------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "Father: \"I know he went through what he went through\" Louis Jordan was found on his sailboat, which was listing and in bad shape, rescuer says . He appears to be in good shape, physically and mentally .\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Pre-Trained BART GENERATION - WITH PROMPT ENGINEERING:\n",
      "Louis Jordan, 37, left Conway, South Carolina, to fish in the ocean. A storm capsized his boat and broke his mast, so he couldn't fix the boat right away. After his food and water ran out, it became an issue of survival. The boat capsized two more times before he was rescued, according to Jordan.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Example  2\n",
      "----------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "(CNN)According to an outside review by Columbia Journalism School professors, \"(a)n institutional failure at Rolling Stone resulted in a deeply flawed article about a purported gang rape at the University of Virginia.\" The Columbia team concluded that \"The failure encompassed reporting, editing, editorial supervision and fact-checking.\" Hardly a ringing endorsement of the editorial process at the publication. The magazine's managing editor, Will Dana, wrote, \"We would like to apologize to our readers and to all of those who were damaged by our story and the ensuing fallout, including members of the Phi Kappa Psi fraternity and UVA administrators and students.\" Brian Stelter: Fraternity to 'pursue all available legal action' The next question is: . Can UVA, Phi Kappa Psi or any of the other fraternities on campus sue for defamation? The Virginia Supreme Court said in Jordan v. Kollman that \"the elements of libel are (1) publication of (2) an actionable statement with (3) the requisite intent.\" \"Actionable\" means the statement must be both false and defamatory. Of course, the law of defamation must be balanced against the freedom of speech protected under not only the First Amendment to the United States Constitution, but also the Virginia Constitution. True statements cannot be defamatory. Neither can pure statements of opinion, because they theoretically cannot be either true or false. But the Rolling Stone article certainly purported to be fact, and it apparently is not exactly what the law considers \"true.\" The individual members of the fraternity will likely be considered private individuals, and not public figures; the latter have a harder time proving defamation. A private person suing for defamation must establish that the defendant has published a false factual statement that is about the person and that it also harms the person's reputation. The private plaintiff also must show that the defendant knew that the statement was false, or believed it was true but lacked a reasonable basis, or acted negligently in checking the facts. At first blush, that sounds like it fits perfectly, right? The Columbia report may go a long way toward establishing at least a modicum of the required intent. But that's only half the battle. There are strict rules about who can be a plaintiff in a defamation action like this. The identity of the aspiring plaintiff matters. First, let's eliminate UVA. The university is a public university, and therefore it is a governmental entity. The Supreme Court has been clear on the issue of libelous statements about the government: The government cannot sue for defamation. There is no such cause of action in American jurisprudence. Now the fraternities, starting with Phi Kappa Psi. A fraternity is not an individual, but a group. A plaintiff in a defamation case must show that the statements were \"of or concerning\" the plaintiff. It sounds obvious, but if you're going to say a statement hurt you, you have to prove the statement actually was about you to begin with. When the statements are about a group without naming an individual, it's hard to say the statement is \"concerning\" the individual -- and groups generally cannot sue.  For example, you can be sued if you call a specific lawyer a thief, but that same person cannot sue you if you simply call all lawyers thieves. Defamatory statements about a group are therefore not actionable by the group's individual members, for the most part. Like all rules, however, there are exceptions. If the defamatory language is about \"a comparatively small group of persons and the defamatory part is easily imputed against all members of the small group, an individual member may sue.\" If I said, \"The 1980 Philadelphia Phillies infielders were a bunch of criminals\" (they weren't),  the individual players could sue, because that mean statement is clearly about certain persons -- if I said that -- which I didn't. Phi Kappa Psi would likely argue that the \"small group\" exception fits it perfectly: Even if the individual members were not identified by name, the defamatory story has been imputed directly to individual members, who have suffered by their association with the group. On the other hand, Rolling Stone's lawyers would likely argue that the group is so large and fluid (after all, the membership changes somewhat every year), that even though the fraternity's reputation is tarnished, the members have suffered no individualized injury. As for the other fraternities on campus but not implicated in the story, that's likely a group that moves from the small category to large, and the members of Greek life generally will have a harder time bringing a lawsuit. Lawyers will tell you that a libel suit is one of those things that citizens often threaten each other with on Facebook, but that such cases are rarely actually filed. That's because a plaintiff usually has to show some kind of financial harm. So if your Aunt Edna calls you a loser on Twitter, you're going to have to spend money on an expert to explain to a jury how that actually damaged you financially. And since most of the people who waste time threatening each other with defamation suits  on Facebook live in their moms' basements and are \"between jobs,\" these are not the kind of people who have money or reputation to damage in the first place. The UVA situation is not your run-of-the-mill defamation case. The university won't be able to sue, but if the members of the fraternity can get past some of the preliminary hurdles of a defamation claim, and they can make a tangible case for damages, then this could be one of those rare successful defamation cases.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "An outside review found that a Rolling Stone article about campus rape was \"deeply flawed\" Danny Cevallos says that there are obstacles to a successful libel case, should one be filed .\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Pre-Trained BART GENERATION - WITH PROMPT ENGINEERING:\n",
      "Rolling Stone article about alleged gang rape at University of Virginia drew criticism. Peter Bergen: Can UVA, Phi Kappa Psi or any of the other fraternities on campus sue for defamation? He says the law of defamation must be balanced against the freedom of speech protected under the First Amendment.Bergen: The identity of the aspiring plaintiff matters.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_indices = [20, 50]\n",
    "\n",
    "for i, index in enumerate(example_indices):\n",
    "    dialogue = dataset['test'][index]['article']\n",
    "    summary = dataset['test'][index]['highlights']\n",
    "\n",
    "    prefix = 'Summarize the article in one or two sentences? :  '\n",
    "    \n",
    "    inputs = tokenizer(prefix + dialogue, max_length=512, truncation=True, return_tensors='pt')\n",
    "    output = tokenizer.decode(\n",
    "        model.generate(\n",
    "            inputs[\"input_ids\"], \n",
    "            max_new_tokens=250,\n",
    "        )[0], \n",
    "        skip_special_tokens=True\n",
    "    )\n",
    "    \n",
    "    print(dash_line)\n",
    "    print('Example ', i + 1)\n",
    "    print(dash_line)\n",
    "    print(f'INPUT PROMPT:\\n{dialogue}')\n",
    "    print(dash_line)\n",
    "    print(f'BASELINE HUMAN SUMMARY:\\n{summary}')\n",
    "    print(dash_line)\n",
    "    print(f'Pre-Trained BART GENERATION - WITH PROMPT ENGINEERING:\\n{output}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60965364-4494-48d0-8dcd-9118cd241ce8",
   "metadata": {},
   "source": [
    "The original model struggles to reduce the summarisations to below 3 or 4 sentences. The CNN_daily mail dataset contains highlights that summarise the article in 1 or two sentences. \n",
    "\n",
    "With some basic prompt engineering the model still stuggles to reduce this further. This could possibly be improved with some fine tuning which is what we will try now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc55fb8-27fb-4ecc-a054-a98d2128d3f0",
   "metadata": {},
   "source": [
    "### First we should get some baseline metrics for the original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff907923-067d-45d2-a16a-aa6e4006e977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up evaluation metric \n",
    "import evaluate\n",
    "rouge = evaluate.load(\"rouge\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6fa8c042-7a96-4246-bc31-b8bdef40d810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Highlights</th>\n",
       "      <th>original_model_summaries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Membership gives the ICC jurisdiction over all...</td>\n",
       "      <td>Palestiniania. The move was made official. The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Theia, a bully breed mix, was apparently hit b...</td>\n",
       "      <td>A. The dog was hit by a car. The dog was burie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mohammad Javad Zarif has spent more time with ...</td>\n",
       "      <td>Moh. He is Iran's foreign minister. He is know...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17 Americans were exposed to the Ebola virus w...</td>\n",
       "      <td>The. The five were exposed to Ebola in Sierra ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Student is no longer on Duke University campus...</td>\n",
       "      <td>The. The student admitted to hanging the noose...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Manuscript of \"American Pie\" lyrics is sold to...</td>\n",
       "      <td>Don. Don McLean's song is 44-year. Christie's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Letourneau Fualaau had a sexual relationship w...</td>\n",
       "      <td>Mary. Mary Kay Kay Kay Letourneau Letour-Letou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Don McLean's \"American Pie\" lyrics auctioned f...</td>\n",
       "      <td>The. The song is one of the most dissected in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Mindy Kaling's brother Vijay Chokalingam prete...</td>\n",
       "      <td>Vay Chokalingam applied to St. Chokalingam pos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The actor says he's not planning on seeing the...</td>\n",
       "      <td>T,. Travolt: \"I've been so happy with my (Scie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Highlights  \\\n",
       "0   Membership gives the ICC jurisdiction over all...   \n",
       "1   Theia, a bully breed mix, was apparently hit b...   \n",
       "2   Mohammad Javad Zarif has spent more time with ...   \n",
       "3   17 Americans were exposed to the Ebola virus w...   \n",
       "4   Student is no longer on Duke University campus...   \n",
       "..                                                ...   \n",
       "95  Manuscript of \"American Pie\" lyrics is sold to...   \n",
       "96  Letourneau Fualaau had a sexual relationship w...   \n",
       "97  Don McLean's \"American Pie\" lyrics auctioned f...   \n",
       "98  Mindy Kaling's brother Vijay Chokalingam prete...   \n",
       "99  The actor says he's not planning on seeing the...   \n",
       "\n",
       "                             original_model_summaries  \n",
       "0   Palestiniania. The move was made official. The...  \n",
       "1   A. The dog was hit by a car. The dog was burie...  \n",
       "2   Moh. He is Iran's foreign minister. He is know...  \n",
       "3   The. The five were exposed to Ebola in Sierra ...  \n",
       "4   The. The student admitted to hanging the noose...  \n",
       "..                                                ...  \n",
       "95  Don. Don McLean's song is 44-year. Christie's ...  \n",
       "96  Mary. Mary Kay Kay Kay Letourneau Letour-Letou...  \n",
       "97  The. The song is one of the most dissected in ...  \n",
       "98  Vay Chokalingam applied to St. Chokalingam pos...  \n",
       "99  T,. Travolt: \"I've been so happy with my (Scie...  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting a su\n",
    "\n",
    "articles = dataset['test'][0:100]['article']\n",
    "highlights = dataset['test'][0:100]['highlights']\n",
    "\n",
    "original_model_summaries = []\n",
    "instruct_model_summaries = []\n",
    "\n",
    "for _, article in enumerate(articles):\n",
    "    prompt = f\"\"\"\n",
    "    'Summarize in one or two sentences the following article: '\n",
    "\n",
    "    {article}\n",
    "\n",
    "    Summary: \"\"\"\n",
    "    \n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512).input_ids\n",
    "\n",
    "    # Generate summary\n",
    "    original_model_outputs = model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
    "    original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
    "    original_model_summaries.append(original_model_text_output)\n",
    "\n",
    "    \n",
    "zipped_summaries = list(zip(highlights, original_model_summaries))\n",
    " \n",
    "df = pd.DataFrame(zipped_summaries, columns = ['Highlights', 'original_model_summaries'])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "03ba97a8-11c9-401b-97ff-74bc86080900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     Palestiniania. The move was made official. The...\n",
      "1     A. The dog was hit by a car. The dog was burie...\n",
      "2     Moh. He is Iran's foreign minister. He is know...\n",
      "3     The. The five were exposed to Ebola in Sierra ...\n",
      "4     The. The student admitted to hanging the noose...\n",
      "                            ...                        \n",
      "95    Don. Don McLean's song is 44-year. Christie's ...\n",
      "96    Mary. Mary Kay Kay Kay Letourneau Letour-Letou...\n",
      "97    The. The song is one of the most dissected in ...\n",
      "98    Vay Chokalingam applied to St. Chokalingam pos...\n",
      "99    T,. Travolt: \"I've been so happy with my (Scie...\n",
      "Name: original_model_summaries, Length: 100, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['original_model_summaries'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bf9d65d8-86fd-4faf-817d-6cc1ec0920bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL MODEL:\n",
      "{'rouge1': np.float64(0.19090482977059542), 'rouge2': np.float64(0.0748375366841095), 'rougeL': np.float64(0.15159647802571558), 'rougeLsum': np.float64(0.15146151773990352)}\n"
     ]
    }
   ],
   "source": [
    "original_model_results = rouge.compute(\n",
    "    predictions=original_model_summaries,\n",
    "    references=highlights[0:len(original_model_summaries)],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print('ORIGINAL MODEL:')\n",
    "print(original_model_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "209253dc-54b7-4341-b950-510bbb68ef57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['article', 'highlights', 'id'],\n",
       "    num_rows: 11490\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d69b9b5e-dd88-4a5d-a4d2-a6a8fe90b7b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['article', 'highlights', 'id', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 287113\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['article', 'highlights', 'id', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 13368\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['article', 'highlights', 'id', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 11490\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4cd13433-8b7b-4494-9b4f-5d808c64f637",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 287113/287113 [02:30<00:00, 1910.13 examples/s]\n",
      "Filter: 100%|██████████| 13368/13368 [00:06<00:00, 1995.72 examples/s]\n",
      "Filter: 100%|██████████| 11490/11490 [00:05<00:00, 1954.81 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset_reduced = tokenized_datasets.filter(lambda example, index: index % 25 == 0, with_indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a47976bd-3fae-4ce7-887a-ea2b52eb35b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['article', 'highlights', 'id', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 11485\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['article', 'highlights', 'id', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 535\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['article', 'highlights', 'id', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 460\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d8d05752-38d6-4ff4-9f2f-16d6b7a9093e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable model parameters: 112361472\n",
      "all model parameters: 406290432\n",
      "percentage of trainable model parameters: 27.66%\n"
     ]
    }
   ],
   "source": [
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
    "\n",
    "print(print_number_of_trainable_model_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "79066052-5c85-46ec-8742-bfb32be3bef8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartForConditionalGeneration(\n",
       "  (model): BartModel(\n",
       "    (shared): BartScaledWordEmbedding(50264, 1024, padding_idx=1)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): BartScaledWordEmbedding(50264, 1024, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x BartEncoderLayer(\n",
       "          (self_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): BartScaledWordEmbedding(50264, 1024, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x BartDecoderLayer(\n",
       "          (self_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=50264, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "19e45805-3398-4cf6-a94f-f5eb1b40e19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tom_r\\anaconda3\\envs\\Generative_AI\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load model and tokenizer\n",
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8dab2b16-d7aa-4254-8170-089820f10c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all encoder layers except the last 2\n",
    "for i, layer in enumerate(model.model.encoder.layers):\n",
    "    if i < len(model.model.encoder.layers) - 2:\n",
    "        for param in layer.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "# Freeze all decoder layers except the last 2\n",
    "for i, layer in enumerate(model.model.decoder.layers):\n",
    "    if i < len(model.model.decoder.layers) - 2:\n",
    "        for param in layer.parameters():\n",
    "            param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a19f4ffb-466a-4fa6-b27f-b67d8f7b1ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable model parameters: 112361472\n",
      "all model parameters: 406290432\n",
      "percentage of trainable model parameters: 27.66%\n"
     ]
    }
   ],
   "source": [
    "print(print_number_of_trainable_model_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9caa1e42-e71a-4992-9aff-88dcd9d46b4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tom_r\\anaconda3\\envs\\Generative_AI\\Lib\\site-packages\\transformers\\training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "output_dir = f'./article-highlight-training-{str(int(time.time()))}'\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    learning_rate=1e-5,  # Lower learning rate\n",
    "    per_device_train_batch_size=4,  # Reduce batch size to fit memory\n",
    "    gradient_accumulation_steps=2,  # Adjust gradient accumulation\n",
    "    num_train_epochs=3,  # Increase epochs to allow for better learning\n",
    "    warmup_steps=50,  # Reduce warmup steps\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_steps=1000,\n",
    "    save_total_limit=3,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset_reduced['train'],\n",
    "    eval_dataset=tokenized_dataset_reduced['validation'],\n",
    "    data_collator=data_collator \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "48954eb9-38be-4e9c-8fd3-be09aab55c56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4308' max='4308' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4308/4308 1:56:58, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.331900</td>\n",
       "      <td>1.575234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.464800</td>\n",
       "      <td>1.563635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.325300</td>\n",
       "      <td>1.573067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.346500</td>\n",
       "      <td>1.579925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.326000</td>\n",
       "      <td>1.585557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.198100</td>\n",
       "      <td>1.588271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.401700</td>\n",
       "      <td>1.588427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.279500</td>\n",
       "      <td>1.592092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
      "There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4308, training_loss=1.3684610853398853, metrics={'train_runtime': 7019.9207, 'train_samples_per_second': 4.908, 'train_steps_per_second': 0.614, 'total_flos': 3.732646362434765e+16, 'train_loss': 1.3684610853398853, 'epoch': 3.0})"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9600ae-29fe-474a-9590-dfd77f4ac11a",
   "metadata": {},
   "source": [
    "## Test out finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2ddb1df4-8a15-46d7-8f5e-053cce3cb885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load finetuned model\n",
    "finetuned_model = BartForConditionalGeneration.from_pretrained(r\"C:\\Users\\tom_r\\Desktop\\Generative-AI\\LLM_Projects\\article-highlight-training-1726671662\\checkpoint-4000\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2e7e68ec-8d37-4f9a-a666-2e714d3ac494",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Example  1\n",
      "----------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "Norfolk, Virginia (CNN)The second mate of the Houston Express probably couldn't believe what he was seeing. Hundreds of miles from land there was a small boat nearby. At first it looked abandoned. It was in bad shape, listing to one side. The crew of the 1,000-foot long container ship thought it was a yacht that had wrecked. Incredibly, as they got closer, they saw there was a man on it, signaling for help. \"He was moving, walking around, waving to us and in surprisingly good condition,\" Capt. Thomas Grenz told CNN by phone Friday. That man, Louis Jordan, 37, had an amazing story. He'd been drifting on the 35-foot Pearson sailboat for more than two months since leaving Conway, South Carolina, to fish in the ocean. Just a few days into his trip, a storm capsized his boat and broke his mast. One of his shoulders was broken, too, so he couldn't fix the boat right away. Eventually he was able to rig a makeshift mast and sail, but he could make little headway against the currents. \"It took so long,\" Jordan said.  \"It moved so slowly.\" The boat capsized two more times before he was rescued, according to Jordan. His father, Frank Jordan, told CNN's Jim Sciutto that he was expecting his son to look different. \"He looked good. Hadn't lost too much weight. He wasn't badly sunburned like I thought he probably would be,\" he said. Lost at sea for 66 days . After his food and water ran out, it became an issue of survival. Collecting fresh water was a nightmare for Jordan.  The weather wouldn't cooperate. Records show there were more than a dozen storms off the coast of the Carolinas during the time he was missing. The precipitation came at night during harsh conditions. \"I had tried to collect (rain)water ... but every time the waves would splash into the boat,\" Jordan said.  \"The waves would put saltwater into my freshwater and it tasted bad. \"Finally the conditions were right.  I filled up my water tank, which is 25 gallons.  I filled up a bucket.\" Then there was the issue of food. The fish weren't cooperating, but after a while Jordan learned they were attracted to his laundry, which he would put out to sea for a rinse. The fish would swim in and out of his clothes and he could easily scoop them up with a hand net, he said. Jordan came ashore Thursday evening. CNN affiliate WAVY in Norfolk, Virginia, reported that he was able to walk from the helicopter into Sentara Norfolk General Hospital about 7:30 p.m. Coast Guard officials have said they have found no reason to doubt Jordan's incredible story. They noted that his father contacted them January 29 to report his son and his boat missing. Frank Jordan addressed the skepticism about his son's appearance, saying the boat stayed afloat and upright most of the time. His son spent most of his days in the cabin, out of the sun. Frank Jordan said it was obvious when the Jordans met at the hospital Friday morning that his normally low-key and private son had been through an ordeal. \"I know he went through what he went through,\" Frank Jordan said. Jordan is an unemployed truck driver who lived on his boat at a marina in Conway. He had free rent and free food in the river, he said. But when it became difficult to catch dinner, he took off for the ocean in hopes he would land some bigger fish. Frank Jordan told CNN's Wolf Blitzer on Thursday that he had worried about his son, who is an inexperienced sailor, but he held hope because his son had a good boat. And he had the strength to make it. \"He's got a very strong constitution and (is strong) not only physically, but spiritually,\" Frank Jordan said. \"And he told me on the phone that he was praying the whole time, so I believe that sustained him a great deal.\" Rescue swimmer Kyle McCollum was the first to care for Jordan on the flight back to land. \"You would expect sunburns, severe sunburn, blisters maybe ... a bunch of medical issues that could possibly be wrong with him,\" he said. \"But for him to be in his current state was pretty amazing.\" Grenz was also surprised by Jordan's condition, physically and mentally. The rescued sailor knew almost exactly what day it was, remarkable for someone who had been on the water for more than 60 days. Jordan was dehydrated and said he was hungry. \"We took him to a rescue boat,\" the container ship captain said. \"He was given water and pea soup to gain some power again.\" Derriel Morris, a neighbor at the Bucksport Plantation Marina & RV Resort called Jordan a nice guy who loved his 47-year-old boat, named \"Angel.\" Morris said: \"It was immaculate, it was gorgeous, beautifully painted. I mean it looked like a brand new sailboat.\" Morris told CNN affiliate WPDE that one day in January he was going to the store and Jordan asked him to bring back some coffee creamer. But when he returned to the marina, Jordan had slipped away. \"There was no shore line, no hose; it was like he was never there,\" Morris told the station. After he disappeared others who also live there held a candlelight ceremony. The marina's manager, Jeff Weeks, told WPDE that Jordan is expected to be back at Buscksport next week. Tales of people who cheated death after days, weeks adrift .\n",
      "----------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "Father: \"I know he went through what he went through\" Louis Jordan was found on his sailboat, which was listing and in bad shape, rescuer says . He appears to be in good shape, physically and mentally .\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Finetuned BART model:\n",
      "Louis Jordan, 37, had been drifting on the 35-foot Pearson sailboat for more than two months. He'd left Conway, South Carolina, to fish in the ocean. Just a few days into his trip, a storm capsized his boat and broke his mast.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Example  2\n",
      "----------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "(CNN)According to an outside review by Columbia Journalism School professors, \"(a)n institutional failure at Rolling Stone resulted in a deeply flawed article about a purported gang rape at the University of Virginia.\" The Columbia team concluded that \"The failure encompassed reporting, editing, editorial supervision and fact-checking.\" Hardly a ringing endorsement of the editorial process at the publication. The magazine's managing editor, Will Dana, wrote, \"We would like to apologize to our readers and to all of those who were damaged by our story and the ensuing fallout, including members of the Phi Kappa Psi fraternity and UVA administrators and students.\" Brian Stelter: Fraternity to 'pursue all available legal action' The next question is: . Can UVA, Phi Kappa Psi or any of the other fraternities on campus sue for defamation? The Virginia Supreme Court said in Jordan v. Kollman that \"the elements of libel are (1) publication of (2) an actionable statement with (3) the requisite intent.\" \"Actionable\" means the statement must be both false and defamatory. Of course, the law of defamation must be balanced against the freedom of speech protected under not only the First Amendment to the United States Constitution, but also the Virginia Constitution. True statements cannot be defamatory. Neither can pure statements of opinion, because they theoretically cannot be either true or false. But the Rolling Stone article certainly purported to be fact, and it apparently is not exactly what the law considers \"true.\" The individual members of the fraternity will likely be considered private individuals, and not public figures; the latter have a harder time proving defamation. A private person suing for defamation must establish that the defendant has published a false factual statement that is about the person and that it also harms the person's reputation. The private plaintiff also must show that the defendant knew that the statement was false, or believed it was true but lacked a reasonable basis, or acted negligently in checking the facts. At first blush, that sounds like it fits perfectly, right? The Columbia report may go a long way toward establishing at least a modicum of the required intent. But that's only half the battle. There are strict rules about who can be a plaintiff in a defamation action like this. The identity of the aspiring plaintiff matters. First, let's eliminate UVA. The university is a public university, and therefore it is a governmental entity. The Supreme Court has been clear on the issue of libelous statements about the government: The government cannot sue for defamation. There is no such cause of action in American jurisprudence. Now the fraternities, starting with Phi Kappa Psi. A fraternity is not an individual, but a group. A plaintiff in a defamation case must show that the statements were \"of or concerning\" the plaintiff. It sounds obvious, but if you're going to say a statement hurt you, you have to prove the statement actually was about you to begin with. When the statements are about a group without naming an individual, it's hard to say the statement is \"concerning\" the individual -- and groups generally cannot sue.  For example, you can be sued if you call a specific lawyer a thief, but that same person cannot sue you if you simply call all lawyers thieves. Defamatory statements about a group are therefore not actionable by the group's individual members, for the most part. Like all rules, however, there are exceptions. If the defamatory language is about \"a comparatively small group of persons and the defamatory part is easily imputed against all members of the small group, an individual member may sue.\" If I said, \"The 1980 Philadelphia Phillies infielders were a bunch of criminals\" (they weren't),  the individual players could sue, because that mean statement is clearly about certain persons -- if I said that -- which I didn't. Phi Kappa Psi would likely argue that the \"small group\" exception fits it perfectly: Even if the individual members were not identified by name, the defamatory story has been imputed directly to individual members, who have suffered by their association with the group. On the other hand, Rolling Stone's lawyers would likely argue that the group is so large and fluid (after all, the membership changes somewhat every year), that even though the fraternity's reputation is tarnished, the members have suffered no individualized injury. As for the other fraternities on campus but not implicated in the story, that's likely a group that moves from the small category to large, and the members of Greek life generally will have a harder time bringing a lawsuit. Lawyers will tell you that a libel suit is one of those things that citizens often threaten each other with on Facebook, but that such cases are rarely actually filed. That's because a plaintiff usually has to show some kind of financial harm. So if your Aunt Edna calls you a loser on Twitter, you're going to have to spend money on an expert to explain to a jury how that actually damaged you financially. And since most of the people who waste time threatening each other with defamation suits  on Facebook live in their moms' basements and are \"between jobs,\" these are not the kind of people who have money or reputation to damage in the first place. The UVA situation is not your run-of-the-mill defamation case. The university won't be able to sue, but if the members of the fraternity can get past some of the preliminary hurdles of a defamation claim, and they can make a tangible case for damages, then this could be one of those rare successful defamation cases.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "An outside review found that a Rolling Stone article about campus rape was \"deeply flawed\" Danny Cevallos says that there are obstacles to a successful libel case, should one be filed .\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Finetuned BART model:\n",
      "David Perry: Rolling Stone article about alleged gang rape at UVA has been widely criticized. Perry: Can UVA, Phi Kappa Psi or other fraternities sue for defamation? He says there are strict rules about who can be a plaintiff in a defamation action like this. Perry says the identity of the aspiring plaintiff matters. He says the law of defamation must be balanced against freedom of speech.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Example  3\n",
      "----------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "(CNN)When I was elected to the Kentucky State Senate in 1967, I became the first woman and the first person of color to serve in the body.  Five decades later, I find it almost unfathomable that a politician from my own state is attempting to launch his presidential campaign on a record that includes questioning landmark voting rights and civil rights legislation. But that is what Rand Paul, who today declared he's running for president of the United States, is doing. His campaign team told reporters last week that his campaign announcement message would be about \"expanding the Republican Party\" -- a message of inclusion. But those of us listening today who he is hoping to include, heard nothing more than hype. I'm not buying it. Since coming to the U.S. Senate, Paul has tried to sell himself as a different type of Republican.  He's tried to brand himself as the GOP's minority outreach candidate.  The problem for Paul, and the GOP at large, is that they don't back up their words with their policies. Yes, it's about time that Republicans started seriously considering the fact that black voters are an important piece of the electoral puzzle.  But they can't actually appeal to the community unless they have a real commitment to the issues facing minority communities.  A quick survey of Sen. Paul's positions makes clear that he does not. Paul kicked off his announcement speech in Louisville by declaring \"I have a message that is loud and clear:  We have come to take our country back.\"  I have no doubt that under Paul's leadership, he would indeed take our country back -- in the wrong direction -- way back to a time when we were debating the Civil Rights Act --  which Paul has done since landing on the national stage; when there was no Department of Education -- a department he thinks \"should be done away with;\" when women didn't have choices -- choices Paul seeks to limit in Washington; when DREAMers weren't protected from deportation -- protections Paul currently opposes. In his inept speaking engagements at historically black colleges and universities, he has come across as condescending and lacking basic cultural competency. But Paul has also questioned the Civil Rights Act, and even claimed that private business owners have a right to discriminate. When asked about the need for a more robust Voting Rights Act following the Supreme Court's dismantling of the law, Paul dismissively remarked, \"We have an African-American President.\" When President Obama stood with John Lewis and other veterans of the civil rights movement in front of the Edmund Pettus Bridge last month to mark the 50th anniversary of Bloody Sunday, he inspired us all by saying: \"With effort, we can roll back poverty and the roadblocks to opportunity. ... With effort, we can protect the foundation stone of our democracy for which so many marched across this bridge -- and that is the right to vote.\" America is better -- and we solve more problems -- with more democracy, not less.  Unfortunately Rand Paul has demonstrated that he disagree with that basic principle.  Paul tried once again from that stage in Louisville to fashion himself as the one member of his party courageous enough to try to broaden Republican appeal to constituencies they ignore year after year. But his record makes it very clear that his views are outdated, outside of the mainstream, and disqualifying for a man who wants to lead our country. The American people deserve a leader who won't disrespect their intelligence, who won't pander to them when it's convenient, and who won't work to dismantle the progress we have made over the last five decades. What I heard today, didn't change the facts about Rand Paul's record.  The American people deserve better than Rand Paul.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "Georgia Powers: Rand Paul, running for president, would like minorities to think he's an advocate. His record on rights shows otherwise . On civil rights, women's choice, voting rights, immigrant DREAMers, education, he has shown he'd take country backwards, she says .\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Finetuned BART model:\n",
      "Sen. Rand Paul announced he's running for president. Rand Paul has tried to brand himself as the GOP's minority outreach candidate, says Donna Brazile. Brazile: Paul has also questioned the Civil Rights Act, and even claimed that private business owners have a right to discriminate.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Example  4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "(CNN)Anthony Ray Hinton is thankful to be free after nearly 30 years on Alabama's death row for murders he says he didn't commit. And incredulous that it took so long. Hinton, 58, looked up, took in the sunshine and thanked God and his lawyers Friday morning outside the county jail in Birmingham, minutes after taking his first steps as a free man since 1985. He spoke of unjustly losing three decades of his life, under fear of execution, for something he didn't do. \"All they had to do was to test the gun, but when you think you're high and mighty and you're above the law, you don't have to answer to nobody,\" Hinton told reporters. \"But I've got news for you -- everybody that played a part in sending me to death row, you will answer to God.\" Jefferson County Circuit Court Judge Laura Petro had ordered Hinton released after granting the state's motion to dismiss charges against him. Hinton was convicted of murder in the 1985 deaths of two Birmingham-area, fast-food restaurant managers, John Davidson and Thomas Wayne Vason. But a new trial was ordered in 2014 after firearms experts testified 12 years earlier that the revolver Hinton was said to have used in the crimes could not be matched to evidence in either case, and the two killings couldn't be linked to each other. \"Death Row Stories\": Hard questions about the U.S. capital punishment system . The state then declined to re-prosecute the case. Hinton was 29 at the time of the killings and had always maintained his innocence, said the Equal Justice Initiative, a group that helped win his release. \"Race, poverty, inadequate legal assistance, and prosecutorial indifference to innocence conspired to create a textbook example of injustice,\" Bryan Stevenson, the group's executive director and Hinton's lead attorney, said of his African-American client. \"I can't think of a case that more urgently dramatizes the need for reform than what has happened to Anthony Ray Hinton.\" Stevenson said the \"refusal of state prosecutors to re-examine this case despite persuasive and reliable evidence of innocence is disappointing and troubling.\" Amnesty report: Executions down but death sentences on the rise . Dressed in a dark suit and blue shirt, Hinton praised God for his release, saying he was sent \"not just a lawyer, but the best lawyers.\" He said he will continue to pray for the families of the murder victims. Both he and those families have suffered a miscarriage of justice, he said. \"For all of us that say that we believe in justice, this is the case to start showing, because I shouldn't have (sat) on death row for 30 years,\" he said. Woman who spent 22 years on death row has case tossed . Hinton was accompanied Friday by two of his sisters, one of whom still lives in the Birmingham area. Other siblings will fly to the area to see him soon, Stevenson said. His mother, with whom he lived at the time of his arrest, is no longer living, according to the lawyer. Hinton planned to spend at least this weekend at the home of a close friend. He will meet with his attorneys Monday to start planning for his immediate needs, such as obtaining identification and getting a health checkup, Stevenson said. The plan now is to spend a few weeks to get oriented with freedom and \"sort out what he wants to do,\" Stevenson said.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "Anthony Ray Hinton goes free Friday, decades after conviction for two murders . Court ordered new trial in 2014, years after gun experts testified on his behalf . Prosecution moved to dismiss charges this year .\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Finetuned BART model:\n",
      "Anthony Ray Hinton was convicted of murder in the 1985 deaths of two Birmingham-area, fast-food restaurant managers. A new trial was ordered in 2014 after firearms experts testified 12 years earlier that the revolver could not be matched to evidence in either case. The state then declined to re-prosecute the case.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Example  5\n",
      "----------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "(CNN)Former New England Patriots star Aaron Hernandez will need to keep his lawyers even after being convicted of murder and other charges in the death of Odin Lloyd. The 25-year-old potentially faces three more trials -- one criminal and two civil actions. Next up is another murder trial in which he is accused of killing two men and wounding another person near a Boston nightclub in July 2012. Prosecutors have said Hernandez fatally shot Daniel de Abreu and Safiro Furtado when he fired into their 2003 BMW.  Another passenger was wounded and two others were uninjured. Hernandez pleaded not guilty at his arraignment. The trial was originally slated for May 28, but Jake Wark, spokesman for the Suffolk County District Attorney's Office, said Wednesday the trial had been postponed and no new date had been set. \"We expect to select a new court date in the coming days and then set the amended trial track. The Suffolk indictments allege two counts of first-degree murder for the July 16, 2012, shooting deaths of Daniel de Abreu and Safiro Furtado in Boston's South End; three counts of armed assault with intent to murder and one count of assault and battery by means of a dangerous weapon for shots fired at three surviving victims; and one count of unlawful possession of a firearm,\" he said. The families of de Abreu and Furtado filed civil suits against Hernandez, and a judge froze his $5 million in assets, pending the outcome of the double-murder trial. The freeze includes the disputed $3.3 million signing bonus payment Hernandez claims he is owed by the New England Patriots. Hernandez is also being sued by a man who claims Hernandez shot him while they were in a limousine in Miami in February 2013. Alexander Bradley claims the then-New England Patriot tight end wounded him after the two got into a fight at a Miami strip club. In a lawsuit filed four months later, Bradley said Hernandez fired at him during a limo ride after leaving the club and that Hernandez intentionally \"possessed a gun which he was not legally licensed to have.\" Hernandez's lawyers have argued he couldn't defend himself properly while on trial in Massachusetts. There was no criminal charge in the case. And then there is the grievance over unpaid bonus money filed by the NFL players union on behalf of Hernandez, who signed a contract in 2012 that potentially was worth more than $40 million. If the grievance is heard by the league, Hernandez will be represented by the the National Football League Players' Association. Who was Odin Lloyd? CNN's Lawrence Crook contributed to this report.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "Aaron Hernandez has been found guilty in Odin Lloyd's death, but his troubles are not over . He also faces murder charges in Suffolk County, Massachusetts, but trial was postponed . In addition, Hernandez will face two civil lawsuits; one is in relation to Suffolk County case .\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Finetuned BART model:\n",
      "Aaron Hernandez potentially faces three more trials -- one criminal and two civil actions. He is accused of killing two men and wounding another person near a Boston nightclub in July 2012. Prosecutors have said Hernandez fatally shot Daniel de Abreu and Safiro Furtado when he fired into their 2003 BMW.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Example  6\n",
      "----------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "(CNN)A measles outbreak that affected more than 130 Californians since December is over, the California Department of Public Health declared Friday. It has been 42 days since the last known case of B3 strain of measles, the equivalent of two successive incubation periods, said Dr. Karen Smith, director of the health department. The department said in its latest update that 131 people came down with the B3 strain, and five who had a different genotype than the outbreak strain. Of the 131 cases, the state was able to obtain the vaccination status for 81 patients. Of the 81, 70% were unvaccinated. \"Prompt investigation of cases, interviewing hundreds of contacts of infected people, vaccinating hundreds of at risk people, and increasing awareness among health care providers about measles, helped to control this outbreak,\" Smith said. The outbreak began with dozens of visitors to two Disney theme parks in the state. The health department said 42 of the cases occurred from December 17-20. Two patients with rashes have been identified in April, but they have a different measles genotype. The Centers for Disease Control and Prevention said on its website that 19 different strains have been discovered since 1990. Measles is a highly contagious respiratory disease. It causes fever, red and sore eyes, runny nose, cough and a rash. It can cause deadly health complications, including pneumonia and encephalitis. It  is spread by contact with an infected person through coughing or sneezing. It can remain in the air and on surfaces for up to two hours. CNN's Debra Goldschmidt contributed to this report.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "Officials say 131 Californians were affected by one strain, five by other strains . About 70% of the people who could show health records were unvaccinated . Outbreak began in December among visitors to two Disney theme parks .\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Finetuned BART model:\n",
      "It has been 42 days since the last known case of the B3 strain of measles. Of the 131 cases, the state was able to obtain the vaccination status for 81 patients. The outbreak began with dozens of visitors to two Disney theme parks in the state. Measles is a highly contagious respiratory disease.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Example  7\n",
      "----------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "(CNN)A freshly fallen tree in the roadway was Jason Warnock's first clue. Warnock was driving through a canyon in Lewiston, Idaho, on Wednesday when he saw the tree, then looked up to see an SUV dangling over the edge of a cliff. The only thing holding the GMC Yukon and its terrified driver from a 30-foot drop was a crumpled chain-link fence, still clinging to the earth above Bryden Canyon Road. \"I seen that guy hanging there and he was trying to beat the window out or the door open and I was like 'Oh man,' 'cause only like five links were hanging there,\" Warnock told KXLY, a CNN affiliate. \"I was like, I gotta do something and no one was doing anything.\" What Warnock did next, captured in a dramatic photo by Lewiston Tribune photographer Barry Kough, made headlines around the world. Warnock dashed from his car and scrambled up a hill to the Yukon and its driver, 23-year-old Matthew Sitko, who appeared to be in shock. \"I got up there and I was like, 'Are you alright man?' He shook his head, yeah. I grabbed my Snap-on multi-tool and it had jagged edges on each end. I hit the window three times and it didn't break. Every time I hit it, the thing rocked like it was going to fall off,\" Warnock told KXLY. Sitko was finally able to get the passenger-side window down. Warnock then reached in and pulled Sitko out to safety -- a moment recorded by Kough's camera. Then Warnock disappeared. \"I left and got out of there before anyone knew who I was,\" he said. He remained an unknown good Samaritan, his identity a mystery, until Kough's picture of the daring rescue appeared in the Lewiston paper and spread across the Internet. \"I don't feel like I deserve any credit or anything,\" Warnock said. \"I just did what anyone would do, went right back to work.\" Thanks to Warnock, Sitko went to the hospital with just minor injuries. \"The Lewiston Police Department would like to thank Jason Warnock for his quick and decisive actions in helping Mr. Sitko and preventing the situation from worsening,\" said Roger Lanier, the interim police chief. Warnock told KXLY he didn't want or expect all the attention and would rather be fishing in the mountains than reading about himself.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "Jason Warnock rescued a man whose SUV was dangling off the edge of a cliff . Warnock: \"I don't feel like I deserve any credit ... I just did what anyone would do\"\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Finetuned BART model:\n",
      "Jason Warnock was driving through a canyon in Lewiston, Idaho, on Wednesday when he saw the tree. The only thing holding the GMC Yukon and its terrified driver from a 30-foot drop was a crumpled chain-link fence. \"I grabbed my Snap-on multi-tool and it had jagged edges on each end,\" he says.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Example  8\n",
      "----------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "(CNN)The mass killings of Armenians in the Ottoman Empire, which began 100 years ago Friday, is said by some scholars and others to have been the first genocide of the 20th century, even though the word \"genocide\" did not exist at the time. The issue of whether to call the killings a genocide is emotional, both for Armenians, who are descended from those killed, and for Turks, the heirs to the Ottomans. For both groups, the question touches as much on national identity as on historical facts. Some Armenians feel their nationhood cannot be fully recognized unless the truth of what happened to their forebears is acknowledged. Some Turks still view the Armenians as having been a threat to the Ottoman Empire in a time of war, and say many people of various ethnicities -- including Turks -- were killed in the chaos of war. In addition, some Turkish leaders fear that acknowledgment of a genocide could lead to demands for huge reparations. So, what do we know about happened in those fateful days? Here are some answers: . The Ottoman Turks, having recently entered World War I on the side of Germany and the Austro-Hungarian Empire, were worried that Armenians living in the Ottoman Empire would offer wartime assistance to Russia. Russia had long coveted control of Constantinople (now Istanbul), which controlled access to the Black Sea -- and therefore access to Russia's only year-round seaports. Many historians agree that the number was about 2 million. However, victims of the mass killings also included some of the 1.8 million Armenians living in the Caucasus under Russian rule, some of whom were massacred by Ottoman forces in 1918 as they marched through East Armenia and Azerbaijan. By 1914, Ottoman authorities were already portraying Armenians as a threat to the empire's security. Then, on the night of April 23-24, 1915, the authorities in Constantinople, the empire's capital, rounded up about 250 Armenian intellectuals and community leaders. Many of them ended up deported or assassinated. April 24, known as Red Sunday, is commemorated as Genocide Remembrance Day by Armenians around the world. Friday is the 100th anniversary of that day. This is a major point of contention. Estimates range from 300,000 to 2 million deaths between 1914 and 1923, with not all of the victims in the Ottoman Empire. But most estimates -- including one of 800,000 between 1915 and 1918, made by Ottoman authorities themselves -- fall between 600,000 and 1.5 million. Whether due to killings or forced deportation, the number of Armenians living in Turkey fell from 2 million in 1914 to under 400,000 by 1922. Almost any way one can imagine. While the  death toll is in dispute, photographs from the era document some mass killings. Some show Ottoman soldiers posing with severed heads, others with them standing amid skulls in the dirt. The victims are reported to have died in mass burnings and by drowning, torture, gas, poison, disease and starvation. Children were reported to have been loaded into boats, taken out to sea and thrown overboard. Rape, too, was frequently reported. In addition, according to the website armenian-genocide.org, \"The great bulk of the Armenian population was forcibly removed from Armenia and Anatolia to Syria, where the vast majority was sent into the desert to die of thirst and hunger.\" No. Genocide was not even a word at the time, much less a legally defined crime. The word \"genocide\" was invented in 1944 by a Polish lawyer named Raphael Lemkin to describe the Nazis' systematic attempt to eradicate Jews from Europe. He formed the word by combining the Greek word for race with the Latin word for killing. Genocide became a crime in 1948, when the United Nations approved the Convention on the Prevention and Punishment of the Crime of Genocide. The definition included acts meant \"to destroy, in whole or in part, a national, ethnical, racial or religious group.\" Armenia, the Vatican, the European Parliament, France, Russia and Canada. Germany is expected to join that group on Friday, the 100th anniversary of the start of the killings. Turkey, the United States, the European Commission, the United Kingdom and the United Nations. A U.N. subcommittee called the killings genocide in 1985, but current U.N. Secretary-General Ban Ki-moon declines to use the word. Also, a year ago, on the eve of the 99th anniversary of Red Sunday, then-Turkish Prime Minister (now-President) Recep Tayyip Erdogan offered condolences for the mass killings, which he said had \"inhumane consequences.\" While Turkey vehemently continues to reject the word \"genocide,\" his remarks went further than those of any previous Turkish leader in acknowledging the suffering of Armenians.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "The 100th anniversary of the start of the mass killings will be commemorated Friday . Turkey and others reject the use of the word \"genocide\" Most estimates of the deaths fall between 600,000 and 1.5 million .\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Finetuned BART model:\n",
      "The mass killings of Armenians in the Ottoman Empire began 100 years ago Friday. The issue of whether to call the killings a genocide is emotional, both for Armenians and Turks. For both groups, the question touches as much on national identity as on historical facts. April 24, known as Red Sunday, is commemorated as Genocide Remembrance Day by Armenians.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_indices = [20, 50, 75, 100, 200, 250, 300, 400]\n",
    "\n",
    "for i, index in enumerate(example_indices):\n",
    "    dialogue = dataset['test'][index]['article']\n",
    "    summary = dataset['test'][index]['highlights']\n",
    "\n",
    "    prefix = 'Summarize in one or two sentences the following article: '\n",
    "    \n",
    "    inputs = tokenizer(prefix + dialogue, max_length=512, truncation=True, return_tensors='pt')\n",
    "    output = tokenizer.decode(\n",
    "        finetuned_model.generate(\n",
    "            inputs[\"input_ids\"], \n",
    "            max_new_tokens=250,\n",
    "        )[0], \n",
    "        skip_special_tokens=True\n",
    "    )\n",
    "    \n",
    "    print(dash_line)\n",
    "    print('Example ', i + 1)\n",
    "    print(dash_line)\n",
    "    print(f'INPUT PROMPT:\\n{dialogue}')\n",
    "    print(dash_line)\n",
    "    print(f'BASELINE HUMAN SUMMARY:\\n{summary}')\n",
    "    print(dash_line)\n",
    "    print(f'Finetuned BART model:\\n{output}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7effa15-b14b-40a1-a50b-2e151feec2aa",
   "metadata": {},
   "source": [
    "### Multi-shot inference\n",
    "\n",
    "Finetuning the model has shown little improvement in shortening the length of the summary to a highlight. I think showing the model some examples during the prompt might aid the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "def122f2-37a6-4d70-a68e-31e7eb65d1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tom_r\\anaconda3\\envs\\Generative_AI\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load model and tokenizer\n",
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "61ccde19-b7bb-49eb-a9f3-8c739f325f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['article', 'highlights', 'id', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 11485\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['article', 'highlights', 'id', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 535\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['article', 'highlights', 'id', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 460\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3f1aeb9c-132f-4a29-9621-d07b77fcb81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompt(example_indices_full, example_index_to_summarize):\n",
    "    prompt = ''\n",
    "    for index in example_indices_full:\n",
    "        article = dataset['test'][index]['article']\n",
    "        highlight = dataset['test'][index]['highlights']\n",
    "        \n",
    "        prompt += f\"\"\"\n",
    "Article:\n",
    "\n",
    "{article}\n",
    "\n",
    "Summarize the article in one or two sentences? \n",
    "{highlight}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    article = dataset['test'][example_index_to_summarize]['article']\n",
    "    \n",
    "    prompt += f\"\"\"\n",
    "Article:\n",
    "\n",
    "{article}\n",
    "\n",
    "Summarize the article in one or two sentences?\n",
    "\"\"\"\n",
    "        \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "4dba07b4-0a6f-4027-8adf-d74507ff5d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Article:\n",
      "\n",
      "(CNN)A high temperature of 63.5 degrees Fahrenheit might sound like a pleasant day in early spring -- unless you're in Antarctica. The chilly continent recorded the temperature (15.5 degrees Celsius) on March 24, possibly the highest ever recorded on Antarctica, according to the Weather Underground. The temperature was recorded at Argentina's Esperanza Base on the northern tip of the Antarctica Peninsula, according to CNN affiliate WTNH. (Note to map lovers: The Argentine base is not geographically part of the South American continent.) The World Meteorological Organization, a specialized United Nations agency, is in the process of setting up an international ad-hoc committee of about 10 blue-ribbon climatologists and meteorologists to begin collecting relevant evidence, said Randy Cerveny, the agency's lead rapporteur of weather and climate extremes and Arizona State University professor of geographical sciences. The committee will examine the equipment used to measure the temperature, whether it was in good working order, whether the correct monitoring procedures were followed, whether the equipment was placed in the correct location and whether the measurement is matched by corresponding records from surrounding stations, Cerveny said. The committee will discuss the issues and make a recommendation to Cerveny, who will make an official finding, probably by late summer or early fall. Researchers who study climate change carefully watch weather changes in the Antarctic region and elsewhere for evidence that the Earth is getting warmer.\n",
      "\n",
      "Summarize the article in one or two sentences? \n",
      "High temperatures are recorded on the northern tip of the Antarctica Peninsula . The World Meteorological Organization will make the final determination .\n",
      "\n",
      "\n",
      "\n",
      "Article:\n",
      "\n",
      "(CNN)Former New England Patriots star Aaron Hernandez will need to keep his lawyers even after being convicted of murder and other charges in the death of Odin Lloyd. The 25-year-old potentially faces three more trials -- one criminal and two civil actions. Next up is another murder trial in which he is accused of killing two men and wounding another person near a Boston nightclub in July 2012. Prosecutors have said Hernandez fatally shot Daniel de Abreu and Safiro Furtado when he fired into their 2003 BMW.  Another passenger was wounded and two others were uninjured. Hernandez pleaded not guilty at his arraignment. The trial was originally slated for May 28, but Jake Wark, spokesman for the Suffolk County District Attorney's Office, said Wednesday the trial had been postponed and no new date had been set. \"We expect to select a new court date in the coming days and then set the amended trial track. The Suffolk indictments allege two counts of first-degree murder for the July 16, 2012, shooting deaths of Daniel de Abreu and Safiro Furtado in Boston's South End; three counts of armed assault with intent to murder and one count of assault and battery by means of a dangerous weapon for shots fired at three surviving victims; and one count of unlawful possession of a firearm,\" he said. The families of de Abreu and Furtado filed civil suits against Hernandez, and a judge froze his $5 million in assets, pending the outcome of the double-murder trial. The freeze includes the disputed $3.3 million signing bonus payment Hernandez claims he is owed by the New England Patriots. Hernandez is also being sued by a man who claims Hernandez shot him while they were in a limousine in Miami in February 2013. Alexander Bradley claims the then-New England Patriot tight end wounded him after the two got into a fight at a Miami strip club. In a lawsuit filed four months later, Bradley said Hernandez fired at him during a limo ride after leaving the club and that Hernandez intentionally \"possessed a gun which he was not legally licensed to have.\" Hernandez's lawyers have argued he couldn't defend himself properly while on trial in Massachusetts. There was no criminal charge in the case. And then there is the grievance over unpaid bonus money filed by the NFL players union on behalf of Hernandez, who signed a contract in 2012 that potentially was worth more than $40 million. If the grievance is heard by the league, Hernandez will be represented by the the National Football League Players' Association. Who was Odin Lloyd? CNN's Lawrence Crook contributed to this report.\n",
      "\n",
      "Summarize the article in one or two sentences?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_indices_full = [40]\n",
    "example_index_to_summarize = 200\n",
    "\n",
    "one_shot_prompt = make_prompt(example_indices_full, example_index_to_summarize)\n",
    "\n",
    "print(one_shot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "11304633-9e57-483d-b93b-da92d736f08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "Aaron Hernandez has been found guilty in Odin Lloyd's death, but his troubles are not over . He also faces murder charges in Suffolk County, Massachusetts, but trial was postponed . In addition, Hernandez will face two civil lawsuits; one is in relation to Suffolk County case .\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION - ONE SHOT:\n",
      "The temperature was recorded at Argentina's Esperanza Base on the northern tip of the Antarctica Peninsula. The World Meteorological Organization is in the process of setting up an international ad-hoc committee of about 10 blue-ribbon climatologists and meteorologists. The committee will examine the equipment used to measure the temperature, whether it was in good working order.\n"
     ]
    }
   ],
   "source": [
    "highlight = dataset['test'][example_index_to_summarize]['highlights']\n",
    "\n",
    "inputs = tokenizer(one_shot_prompt, return_tensors='pt')\n",
    "output = tokenizer.decode(\n",
    "    model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        max_new_tokens=200,\n",
    "    )[0], \n",
    "    skip_special_tokens=True\n",
    ")\n",
    "\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{highlight}\\n')\n",
    "print(dash_line)\n",
    "print(f'MODEL GENERATION - ONE SHOT:\\n{output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "7f82ff17-2b0a-491e-a8d8-8a9f9c0a2736",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Article:\n",
      "\n",
      "(CNN)A high temperature of 63.5 degrees Fahrenheit might sound like a pleasant day in early spring -- unless you're in Antarctica. The chilly continent recorded the temperature (15.5 degrees Celsius) on March 24, possibly the highest ever recorded on Antarctica, according to the Weather Underground. The temperature was recorded at Argentina's Esperanza Base on the northern tip of the Antarctica Peninsula, according to CNN affiliate WTNH. (Note to map lovers: The Argentine base is not geographically part of the South American continent.) The World Meteorological Organization, a specialized United Nations agency, is in the process of setting up an international ad-hoc committee of about 10 blue-ribbon climatologists and meteorologists to begin collecting relevant evidence, said Randy Cerveny, the agency's lead rapporteur of weather and climate extremes and Arizona State University professor of geographical sciences. The committee will examine the equipment used to measure the temperature, whether it was in good working order, whether the correct monitoring procedures were followed, whether the equipment was placed in the correct location and whether the measurement is matched by corresponding records from surrounding stations, Cerveny said. The committee will discuss the issues and make a recommendation to Cerveny, who will make an official finding, probably by late summer or early fall. Researchers who study climate change carefully watch weather changes in the Antarctic region and elsewhere for evidence that the Earth is getting warmer.\n",
      "\n",
      "Summarize the article in one or two sentences? \n",
      "High temperatures are recorded on the northern tip of the Antarctica Peninsula . The World Meteorological Organization will make the final determination .\n",
      "\n",
      "\n",
      "\n",
      "Article:\n",
      "\n",
      "Cedar Falls, Iowa (CNN)As aides politely tried to rush Ted Cruz from an event in Cedar Falls to one in Cedar Rapids, Iowa, on Thursday, the presidential candidate continued shaking hands with anyone who wanted to meet him. Finally, after the selfies and conversations started to die down, his aides managed to move him closer to the door when a tall, burly man stopped him. \"Senator,\" he said, \"can I pray with you real quick?\" \"Yeah,\" Cruz said, as he clasped the man's upper arm and the two bowed their heads. It was one of the many moments when Cruz connected with voters on a religious level last week, as the senator from Texas hit the trail in Iowa for the first time as a presidential candidate. Being the only official contender in the race, Cruz drew large crowds during his two-day swing across the state. He's counting on Iowa, known for its vocal and active evangelical base, to propel him forward in what's expected to be a tough competition among a crowded field of GOP candidates. Cruz, himself, displays a pastoral swagger when he is speaking on stage and working a room. The senator regularly avoids using a podium, instead favoring pacing the stage with a wireless microphone, a scene reminiscent of a Sunday morning sermon. When he meets with people after events, he embraces each one's hand with both of his, softens his usually theatric tone and looks people square in the eye -- a familiar interaction between churchgoing Christians and their pastors. The past two winners of Iowa's caucuses rose to victory with support from the Christian right, and Cruz, who announced his bid last month at the well-known Baptist school Liberty University, is aiming to energize that same base and claim the coveted state as his prize. Evangelicals make up a large segment of Iowa's Republican voter bloc. According to a Des Moines Register/Bloomberg Politics poll from January, 44% of likely 2016 Republican caucus-goers said they were born-again or evangelical Christians. Cruz has built a brand as a stalwart conservative willing to buck GOP leadership on fiscal issues, but he showed in Iowa last week that he's also eager to champion social issues at a time when many Republicans are anxious to avoid them. He was one of the loudest defenders of the religious freedom law in Indiana, which came under fire last week for what critics called paving a path to discrimination against gays and lesbians. He described the outrage over the laws as \"shameful\" and an \"assault\" on First Amendment rights. \"There are a lot of people here in Iowa and across the country whose hearts are breaking, watching what has happened in the last two weeks,\" Cruz said Friday night at an event in Des Moines. \"We have seen a grossly unfair vilification of religious liberty.\" RELATED: Republican 2016 hopefuls back Indiana's 'religious freedom' law . He's more than comfortable talking about his own faith and telling the story of how his father became a Christian and a pastor. Rafael Cruz, who's become a celebrity among Christian conservatives, will frequently visit Iowa over the next year, Cruz told voters. And Cruz's Iowa director, Bryan English, is a former pastor. Cruz's first television ads are appearing this weekend during programs on Fox News and NBC that are pegged to Easter Sunday. In the ad, Cruz talks about the impact of the \"transformative love of Jesus Christ\" on his life. While neither Mike Huckabee, who won Iowa in 2008, nor Rick Santorum, who won in 2012, went on to win the nomination, their successes helped launch them into high-profile battles with the then-front-runners. And with both of them likely running again in 2016, the competition will be stiff. That's why, for Cruz, courting evangelicals is only a component of a three-pronged strategy to win the nomination that also includes dominating the tea party faction and competing for the libertarian base. His stump speech hits on elements that appeal to each faction. He received standing ovations last week for calling to abolish the IRS, and, in a knock against the National Security Agency, he frequently tells audiences to leave their cell phones on so President Obama \"can hear every word I have to say.\" Cruz argued Thursday that the Republican Party needs to bridge the gap between what he described as the Ron Paul-Rand Paul faction of the party -- young libertarian-minded voters -- and the Santorum base -- evangelicals. The two blocs, he said, are \"not necessarily the best of chums.\" \"If we're going to win, we've got to bring that coalition together,\" he said in Cedar Falls. \"And I think we can do that.\" Cruz frequently says he wants to see a return of the evangelical vote to 2004 levels, when more than six in 10 evangelicals voted in the presidential election, a higher than normal turnout for the demographic. That number has waned slightly since 2004 -- but it's not too far off from the 56% of the overall population that voted in 2012. Still, his campaign believes that if it can tap into the group of evangelicals who've been staying home and get the demographic as a whole to overperform, then that could mean the difference of millions more at the polls. \"If you look at available places for the party to expand the vote, it doesn't exist in the middle, it exists in the evangelical vote,\" said Rick Tyler, a top Cruz adviser. \"It isn't a pond, it's an unfished ocean of available voters who are conservative.\" Russell Moore, president of the Ethics & Religious Liberty Commission of the Southern Baptist Convention, said he expects to see record turnout among evangelicals in 2016 no matter who the nominee is or what that person says. Moore points to hot-button topics like religious freedom issues in the U.S., as well as increased attention to the killing of minority Christians in the Middle East and rising anti-Semitism. \"I don't think a candidate is going to be able to get very far simply by using evangelical lingo or by pointing to his or her personal faith,\" Moore said. \"I think a candidate is going to have to explain how he or she would protect religious liberty and would appoint justices and judges who will maintain the common good.\" Later in April, voters in Iowa will see the bulk of the GOP field tackle these issues when they take the stage at an event hosted by the Iowa Faith and Freedom Coalition. While the past two winners of the Iowa caucuses -- Santorum and Huckabee -- are likely running for president again, Steve Scheffler, president of the group, argued that the field is wide open in terms of who's going to win favor among evangelicals. Jeb Bush, while not popular among conservative activists, was known for his staunch anti-abortion record as Florida governor and touts his Catholic faith as a big force behind his policy views. Scott Walker is the son of a pastor. Ben Carson, the former neurosurgeon, rose to fame in conservative circles after criticizing the Obama administration at a national prayer breakfast. And other likely candidates -- from Marco Rubio to Rick Perry to Rand Paul -- have made serious efforts to court the religious right. \"It's up for grabs. It's a clean slate regardless of if you've run before,\" Scheffler said. \"Naturally those two (Huckabee and Santorum) have the name recognition and database of people who supported them in the past, but by and large voters are going to say, 'Let me take a good look at all of these candidates.'\"\n",
      "\n",
      "Summarize the article in one or two sentences? \n",
      "Ted Cruz has built a brand as a stalwart conservative on fiscal issues . But he's also eager to champion social issues at a time when many Republicans are eager to avoid them . Cruz says the GOP needs to unite young libertarian-minded voters and evangelicals .\n",
      "\n",
      "\n",
      "\n",
      "Article:\n",
      "\n",
      "(CNN)A 32-year-old Massachusetts man is facing murder charges, authorities said Wednesday, four days after another man's remains were found in a duffel bag. The Middlesex District Attorney's Office said that Carlos Colina, 32, will be arraigned the morning of April 14 for murder in connection with the remains discovered Saturday in Cambridge. Earlier this week, Colina was arraigned on charges of assault and battery causing serious bodily injury and improper disposal of a body. A Middlesex County judge then revoked bail for Colina in another case he's involved in, for alleged assault and battery. The victim in that case is different from the one whose remains were found in recent days. Police were notified Saturday morning about a suspicious item along a walkway in Cambridge. Officers arrived at the scene, opened a duffel bag and found human remains. After that discovery, police say, a surveillance video led them to an apartment building, where more body parts were discovered in a common area. That location is near the Cambridge Police Department headquarters. The remains at both locations belonged to the same victim, identified Monday as Jonathan Camilien, 26. Camilien and Colina knew each other, according to authorities. \"This was a gruesome discovery,\" District Attorney Marian Ryan said. CNN's Kevin Conlon contributed to this report.\n",
      "\n",
      "Summarize the article in one or two sentences? \n",
      "Prosecutor: Carlos Colina, 32, will be arraigned on the murder charge next week . He's already been arraigned for alleged assault and battery, improper disposal of a body . Body parts were found in a duffel bag and a common area of an apartment building .\n",
      "\n",
      "\n",
      "\n",
      "Article:\n",
      "\n",
      "(CNN)Former New England Patriots star Aaron Hernandez will need to keep his lawyers even after being convicted of murder and other charges in the death of Odin Lloyd. The 25-year-old potentially faces three more trials -- one criminal and two civil actions. Next up is another murder trial in which he is accused of killing two men and wounding another person near a Boston nightclub in July 2012. Prosecutors have said Hernandez fatally shot Daniel de Abreu and Safiro Furtado when he fired into their 2003 BMW.  Another passenger was wounded and two others were uninjured. Hernandez pleaded not guilty at his arraignment. The trial was originally slated for May 28, but Jake Wark, spokesman for the Suffolk County District Attorney's Office, said Wednesday the trial had been postponed and no new date had been set. \"We expect to select a new court date in the coming days and then set the amended trial track. The Suffolk indictments allege two counts of first-degree murder for the July 16, 2012, shooting deaths of Daniel de Abreu and Safiro Furtado in Boston's South End; three counts of armed assault with intent to murder and one count of assault and battery by means of a dangerous weapon for shots fired at three surviving victims; and one count of unlawful possession of a firearm,\" he said. The families of de Abreu and Furtado filed civil suits against Hernandez, and a judge froze his $5 million in assets, pending the outcome of the double-murder trial. The freeze includes the disputed $3.3 million signing bonus payment Hernandez claims he is owed by the New England Patriots. Hernandez is also being sued by a man who claims Hernandez shot him while they were in a limousine in Miami in February 2013. Alexander Bradley claims the then-New England Patriot tight end wounded him after the two got into a fight at a Miami strip club. In a lawsuit filed four months later, Bradley said Hernandez fired at him during a limo ride after leaving the club and that Hernandez intentionally \"possessed a gun which he was not legally licensed to have.\" Hernandez's lawyers have argued he couldn't defend himself properly while on trial in Massachusetts. There was no criminal charge in the case. And then there is the grievance over unpaid bonus money filed by the NFL players union on behalf of Hernandez, who signed a contract in 2012 that potentially was worth more than $40 million. If the grievance is heard by the league, Hernandez will be represented by the the National Football League Players' Association. Who was Odin Lloyd? CNN's Lawrence Crook contributed to this report.\n",
      "\n",
      "Summarize the article in one or two sentences?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_indices_full = [40, 80, 120]\n",
    "example_index_to_summarize = 200\n",
    "\n",
    "few_shot_prompt = make_prompt(example_indices_full, example_index_to_summarize)\n",
    "\n",
    "print(few_shot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "97affc0d-ba34-4787-a55f-0e5683ba6a7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[155], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m summary \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m][example_index_to_summarize][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhighlights\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(few_shot_prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m output \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(\n\u001b[1;32m----> 5\u001b[0m     model\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m      6\u001b[0m         inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      7\u001b[0m         max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[0;32m      8\u001b[0m     )[\u001b[38;5;241m0\u001b[39m], \n\u001b[0;32m      9\u001b[0m     skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(dash_line)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBASELINE HUMAN SUMMARY:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msummary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Generative_AI\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Generative_AI\\Lib\\site-packages\\transformers\\generation\\utils.py:1745\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_attention_mask_for_generation(\n\u001b[0;32m   1740\u001b[0m         inputs_tensor, generation_config\u001b[38;5;241m.\u001b[39m_pad_token_tensor, generation_config\u001b[38;5;241m.\u001b[39m_eos_token_tensor\n\u001b[0;32m   1741\u001b[0m     )\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m model_kwargs:\n\u001b[0;32m   1744\u001b[0m     \u001b[38;5;66;03m# if model is encoder decoder encoder_outputs are created and added to `model_kwargs`\u001b[39;00m\n\u001b[1;32m-> 1745\u001b[0m     model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_encoder_decoder_kwargs_for_generation(\n\u001b[0;32m   1746\u001b[0m         inputs_tensor, model_kwargs, model_input_name, generation_config\n\u001b[0;32m   1747\u001b[0m     )\n\u001b[0;32m   1749\u001b[0m \u001b[38;5;66;03m# 5. Prepare `input_ids` which will be used for auto-regressive generation\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Generative_AI\\Lib\\site-packages\\transformers\\generation\\utils.py:549\u001b[0m, in \u001b[0;36mGenerationMixin._prepare_encoder_decoder_kwargs_for_generation\u001b[1;34m(self, inputs_tensor, model_kwargs, model_input_name, generation_config)\u001b[0m\n\u001b[0;32m    547\u001b[0m encoder_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    548\u001b[0m encoder_kwargs[model_input_name] \u001b[38;5;241m=\u001b[39m inputs_tensor\n\u001b[1;32m--> 549\u001b[0m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m]: ModelOutput \u001b[38;5;241m=\u001b[39m encoder(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mencoder_kwargs)\n\u001b[0;32m    551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_kwargs\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Generative_AI\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Generative_AI\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Generative_AI\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1061\u001b[0m, in \u001b[0;36mBartEncoder.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1058\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1059\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tokens(input_ids)\n\u001b[1;32m-> 1061\u001b[0m embed_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_positions(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m   1062\u001b[0m embed_pos \u001b[38;5;241m=\u001b[39m embed_pos\u001b[38;5;241m.\u001b[39mto(inputs_embeds\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   1064\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m embed_pos\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Generative_AI\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Generative_AI\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Generative_AI\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:115\u001b[0m, in \u001b[0;36mBartLearnedPositionalEmbedding.forward\u001b[1;34m(self, input_ids, past_key_values_length)\u001b[0m\n\u001b[0;32m    110\u001b[0m bsz, seq_len \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    111\u001b[0m positions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\n\u001b[0;32m    112\u001b[0m     past_key_values_length, past_key_values_length \u001b[38;5;241m+\u001b[39m seq_len, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m    113\u001b[0m )\u001b[38;5;241m.\u001b[39mexpand(bsz, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 115\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mforward(positions \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moffset)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Generative_AI\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:164\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39membedding(\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_idx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_norm,\n\u001b[0;32m    166\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_type, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_grad_by_freq, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparse)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Generative_AI\\Lib\\site-packages\\torch\\nn\\functional.py:2267\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2261\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2262\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2263\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2264\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2265\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2266\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39membedding(weight, \u001b[38;5;28minput\u001b[39m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "summary = dataset['test'][example_index_to_summarize]['highlights']\n",
    "\n",
    "inputs = tokenizer(few_shot_prompt, return_tensors='pt')\n",
    "output = tokenizer.decode(\n",
    "    model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        max_new_tokens=50,\n",
    "    )[0], \n",
    "    skip_special_tokens=True\n",
    ")\n",
    "\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n",
    "print(dash_line)\n",
    "print(f'MODEL GENERATION - FEW SHOT:\\n{output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc9fc0c-59a8-4788-b4f1-3ecc7dcdacc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
